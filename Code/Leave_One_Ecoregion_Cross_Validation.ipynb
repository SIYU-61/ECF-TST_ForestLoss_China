{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EuONoImcQf85"
      },
      "outputs": [],
      "source": [
        "# ==================== Part 3: Leave-One-Ecoregion Cross-Validation ====================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
        "import xgboost as xgb\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Install necessary libraries\n",
        "!pip install -q scikit-learn xgboost\n",
        "\n",
        "print(\"Leave-One-Ecoregion Cross-Validation Analysis\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Load real data\n",
        "print(\"Loading real data...\")\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    data_path = '/content/drive/MyDrive/merged_data_by_year).csv'\n",
        "    df = pd.read_csv(data_path)\n",
        "    print(f\"Data loaded successfully: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
        "\n",
        "    # Handle missing values: DELETE rows with missing values\n",
        "    print(\"\\nHandling missing values...\")\n",
        "    original_shape = df.shape\n",
        "    df = df.dropna()\n",
        "    rows_removed = original_shape[0] - df.shape[0]\n",
        "    print(f\"  Rows with missing values removed: {rows_removed}\")\n",
        "    print(f\"  New data shape: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error loading real data: {e}\")\n",
        "    # Use sample data for demonstration\n",
        "    print(\"Using sample data for demonstration...\")\n",
        "    np.random.seed(42)\n",
        "    n_samples = 5000\n",
        "\n",
        "    # Create sample data for 6 ecoregions\n",
        "    ecoregions = ['I01', 'I04', 'I07', 'I21', 'I25', 'I28']\n",
        "    data = []\n",
        "\n",
        "    for i, region in enumerate(ecoregions):\n",
        "        n_region = n_samples // len(ecoregions)\n",
        "\n",
        "        region_data = {\n",
        "            'ID': [region] * n_region,\n",
        "            'NBR': np.random.uniform(500 + i*50, 800 + i*50, n_region),\n",
        "            'NDVI': np.random.uniform(600 + i*30, 900 + i*30, n_region),\n",
        "            'aspect': np.random.uniform(0, 360, n_region),\n",
        "            'elevation': np.random.randint(0 + i*200, 2000 + i*200, n_region),\n",
        "            'slope': np.random.uniform(0 + i*5, 30 + i*5, n_region),\n",
        "            'annual_precip': np.random.uniform(10 + i*2, 20 + i*2, n_region),\n",
        "            'annual_temp': np.random.uniform(-5 + i, 5 + i, n_region),\n",
        "            'b1': np.random.choice([0, 1], n_region, p=[0.7, 0.3])\n",
        "        }\n",
        "\n",
        "        # Add some unique feature patterns for each ecoregion\n",
        "        if i % 2 == 0:\n",
        "            region_data['NBR'] = region_data['NBR'] * 1.2\n",
        "        if i % 3 == 0:\n",
        "            region_data['NDVI'] = region_data['NDVI'] * 0.8\n",
        "\n",
        "        data.append(pd.DataFrame(region_data))\n",
        "\n",
        "    df = pd.concat(data, ignore_index=True)\n",
        "    print(f\"Created sample data: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
        "\n",
        "print(\"\\nData Information:\")\n",
        "print(f\"Number of ecoregions: {df['ID'].nunique()}\")\n",
        "print(f\"Ecoregion distribution:\")\n",
        "print(df['ID'].value_counts())\n",
        "\n",
        "# Data preprocessing function\n",
        "def preprocess_data(df, features):\n",
        "    \"\"\"Preprocess data for training\"\"\"\n",
        "    X = df[features].copy()\n",
        "    y = df['b1'].copy()\n",
        "\n",
        "    # Standardize\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    return X_scaled, y, scaler\n",
        "\n",
        "# Feature selection (excluding NBR_temporal and NDVI_temporal)\n",
        "feature_cols = ['NBR', 'NDVI', 'aspect', 'elevation', 'slope', 'annual_precip', 'annual_temp']\n",
        "\n",
        "# Ensure features exist in dataframe\n",
        "available_features = [f for f in feature_cols if f in df.columns]\n",
        "print(f\"\\nUsing {len(available_features)} available features: {available_features}\")\n",
        "\n",
        "class LeaveOneEcoregionOutValidator:\n",
        "    \"\"\"Leave-One-Ecoregion Cross-Validator\"\"\"\n",
        "\n",
        "    def __init__(self, model_params=None):\n",
        "        if model_params is None:\n",
        "            self.model_params = {\n",
        "                'n_estimators': 100,\n",
        "                'max_depth': 6,\n",
        "                'learning_rate': 0.1,\n",
        "                'random_state': 42,\n",
        "                'n_jobs': -1,\n",
        "                'use_label_encoder': False,\n",
        "                'eval_metric': 'logloss'\n",
        "            }\n",
        "        else:\n",
        "            self.model_params = model_params\n",
        "\n",
        "    def validate(self, df, feature_cols, selected_regions=None):\n",
        "        \"\"\"Perform leave-one-ecoregion validation\"\"\"\n",
        "\n",
        "        # Select ecoregions for validation\n",
        "        if selected_regions is None:\n",
        "            # Select ecoregions with moderate sample size\n",
        "            region_counts = df['ID'].value_counts()\n",
        "            selected_regions = region_counts[region_counts.between(500, 5000)].index.tolist()[:5]\n",
        "\n",
        "        print(f\"Selected {len(selected_regions)} ecoregions for validation: {selected_regions}\")\n",
        "\n",
        "        results = {}\n",
        "\n",
        "        for i, target_region in enumerate(selected_regions, 1):\n",
        "            print(f\"\\n{'='*60}\")\n",
        "            print(f\"Validation {i}/{len(selected_regions)}: Target Ecoregion {target_region}\")\n",
        "            print('='*60)\n",
        "\n",
        "            # Split data\n",
        "            train_df = df[df['ID'] != target_region].copy()\n",
        "            test_df = df[df['ID'] == target_region].copy()\n",
        "\n",
        "            print(f\"Training set: {len(train_df)} samples (from {train_df['ID'].nunique()} ecoregions)\")\n",
        "            print(f\"Test set: {len(test_df)} samples (from ecoregion {target_region})\")\n",
        "\n",
        "            # Preprocess\n",
        "            X_train, y_train, scaler = preprocess_data(train_df, feature_cols)\n",
        "            X_test, y_test, _ = preprocess_data(test_df, feature_cols)\n",
        "\n",
        "            # Create and train model\n",
        "            model = xgb.XGBClassifier(**self.model_params)\n",
        "            model.fit(X_train, y_train)\n",
        "\n",
        "            # Predict\n",
        "            y_pred = model.predict(X_test)\n",
        "            y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "            # Calculate metrics\n",
        "            metrics = self.calculate_metrics(y_test, y_pred, y_pred_proba)\n",
        "\n",
        "            # Record results\n",
        "            results[target_region] = {\n",
        "                'metrics': metrics,\n",
        "                'train_samples': len(train_df),\n",
        "                'test_samples': len(test_df),\n",
        "                'train_regions': train_df['ID'].nunique(),\n",
        "                'model': model,\n",
        "                'scaler': scaler\n",
        "            }\n",
        "\n",
        "            print(f\"Test set performance:\")\n",
        "            print(f\"  Accuracy: {metrics['accuracy']:.4f}\")\n",
        "            print(f\"  F1 Score: {metrics['f1_score']:.4f}\")\n",
        "            print(f\"  AUC-ROC: {metrics['auc_roc']:.4f}\")\n",
        "            print(f\"  Precision: {metrics['precision']:.4f}\")\n",
        "            print(f\"  Recall: {metrics['recall']:.4f}\")\n",
        "\n",
        "        return results\n",
        "\n",
        "    def calculate_metrics(self, y_true, y_pred, y_pred_proba):\n",
        "        \"\"\"Calculate evaluation metrics\"\"\"\n",
        "        metrics = {\n",
        "            'accuracy': accuracy_score(y_true, y_pred),\n",
        "            'precision': precision_score(y_true, y_pred, zero_division=0),\n",
        "            'recall': recall_score(y_true, y_pred, zero_division=0),\n",
        "            'f1_score': f1_score(y_true, y_pred, zero_division=0)\n",
        "        }\n",
        "\n",
        "        if len(np.unique(y_true)) > 1:\n",
        "            metrics['auc_roc'] = roc_auc_score(y_true, y_pred_proba)\n",
        "        else:\n",
        "            metrics['auc_roc'] = 0.5\n",
        "\n",
        "        return metrics\n",
        "\n",
        "    def analyze_results(self, results):\n",
        "        \"\"\"Analyze leave-one-out validation results\"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"Leave-One-Ecoregion Validation Results Analysis\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        # Create summary table\n",
        "        summary_data = []\n",
        "        for region, result in results.items():\n",
        "            metrics = result['metrics']\n",
        "            summary_data.append({\n",
        "                'Ecoregion': region,\n",
        "                'TestSamples': result['test_samples'],\n",
        "                'Accuracy': metrics['accuracy'],\n",
        "                'F1Score': metrics['f1_score'],\n",
        "                'AUC_ROC': metrics['auc_roc'],\n",
        "                'Precision': metrics['precision'],\n",
        "                'Recall': metrics['recall']\n",
        "            })\n",
        "\n",
        "        summary_df = pd.DataFrame(summary_data)\n",
        "\n",
        "        print(\"\\nLeave-One-Out Validation Performance by Ecoregion:\")\n",
        "        print(summary_df.to_string(index=False))\n",
        "\n",
        "        # Statistical analysis\n",
        "        print(f\"\\nStatistical Analysis:\")\n",
        "        print(f\"Mean Accuracy: {summary_df['Accuracy'].mean():.4f} (±{summary_df['Accuracy'].std():.4f})\")\n",
        "        print(f\"Mean F1 Score: {summary_df['F1Score'].mean():.4f} (±{summary_df['F1Score'].std():.4f})\")\n",
        "        print(f\"Mean AUC-ROC: {summary_df['AUC_ROC'].mean():.4f} (±{summary_df['AUC_ROC'].std():.4f})\")\n",
        "\n",
        "        # Identify worst and best performing ecoregions\n",
        "        worst_region = summary_df.loc[summary_df['Accuracy'].idxmin()]\n",
        "        best_region = summary_df.loc[summary_df['Accuracy'].idxmax()]\n",
        "\n",
        "        print(f\"\\nCross-Ecoregion Transferability Analysis:\")\n",
        "        print(f\"Best performing ecoregion: {best_region['Ecoregion']} (Accuracy: {best_region['Accuracy']:.4f})\")\n",
        "        print(f\"Worst performing ecoregion: {worst_region['Ecoregion']} (Accuracy: {worst_region['Accuracy']:.4f})\")\n",
        "        print(f\"Performance difference: {best_region['Accuracy'] - worst_region['Accuracy']:.4f}\")\n",
        "\n",
        "        # Comparison with within-ecoregion validation (estimated)\n",
        "        print(f\"\\nComparison with Within-Ecoregion Validation (estimated):\")\n",
        "        print(\"(Note: Within-ecoregion validation typically yields higher performance)\")\n",
        "\n",
        "        # Visualization analysis\n",
        "        self.plot_analysis(summary_df, results)\n",
        "\n",
        "        return summary_df\n",
        "\n",
        "    def plot_analysis(self, summary_df, results):\n",
        "        \"\"\"Plot analysis visualizations\"\"\"\n",
        "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "\n",
        "        # 1. Accuracy distribution\n",
        "        axes[0, 0].bar(range(len(summary_df)), summary_df['Accuracy'])\n",
        "        axes[0, 0].axhline(y=summary_df['Accuracy'].mean(), color='r', linestyle='--',\n",
        "                          label=f'Mean: {summary_df[\"Accuracy\"].mean():.3f}')\n",
        "        axes[0, 0].set_xlabel('Ecoregion')\n",
        "        axes[0, 0].set_ylabel('Accuracy')\n",
        "        axes[0, 0].set_title('Leave-One-Out Validation Accuracy by Ecoregion')\n",
        "        axes[0, 0].set_xticks(range(len(summary_df)))\n",
        "        axes[0, 0].set_xticklabels(summary_df['Ecoregion'], rotation=45, ha='right')\n",
        "        axes[0, 0].legend()\n",
        "        axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "        # 2. F1 Score distribution\n",
        "        axes[0, 1].bar(range(len(summary_df)), summary_df['F1Score'])\n",
        "        axes[0, 1].axhline(y=summary_df['F1Score'].mean(), color='r', linestyle='--',\n",
        "                          label=f'Mean: {summary_df[\"F1Score\"].mean():.3f}')\n",
        "        axes[0, 1].set_xlabel('Ecoregion')\n",
        "        axes[0, 1].set_ylabel('F1 Score')\n",
        "        axes[0, 1].set_title('Leave-One-Out Validation F1 Score by Ecoregion')\n",
        "        axes[0, 1].set_xticks(range(len(summary_df)))\n",
        "        axes[0, 1].set_xticklabels(summary_df['Ecoregion'], rotation=45, ha='right')\n",
        "        axes[0, 1].legend()\n",
        "        axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "        # 3. AUC-ROC distribution\n",
        "        axes[0, 2].bar(range(len(summary_df)), summary_df['AUC_ROC'])\n",
        "        axes[0, 2].axhline(y=summary_df['AUC_ROC'].mean(), color='r', linestyle='--',\n",
        "                          label=f'Mean: {summary_df[\"AUC_ROC\"].mean():.3f}')\n",
        "        axes[0, 2].set_xlabel('Ecoregion')\n",
        "        axes[0, 2].set_ylabel('AUC-ROC')\n",
        "        axes[0, 2].set_title('Leave-One-Out Validation AUC-ROC by Ecoregion')\n",
        "        axes[0, 2].set_xticks(range(len(summary_df)))\n",
        "        axes[0, 2].set_xticklabels(summary_df['Ecoregion'], rotation=45, ha='right')\n",
        "        axes[0, 2].legend()\n",
        "        axes[0, 2].grid(True, alpha=0.3)\n",
        "\n",
        "        # 4. Sample size vs performance relationship\n",
        "        axes[1, 0].scatter(summary_df['TestSamples'], summary_df['Accuracy'], s=100, alpha=0.7)\n",
        "        for i, row in summary_df.iterrows():\n",
        "            axes[1, 0].text(row['TestSamples'], row['Accuracy'] + 0.01, row['Ecoregion'],\n",
        "                           ha='center', fontsize=9)\n",
        "\n",
        "        # Add regression line\n",
        "        if len(summary_df) > 1:\n",
        "            z = np.polyfit(summary_df['TestSamples'], summary_df['Accuracy'], 1)\n",
        "            p = np.poly1d(z)\n",
        "            x_range = np.linspace(summary_df['TestSamples'].min(), summary_df['TestSamples'].max(), 100)\n",
        "            axes[1, 0].plot(x_range, p(x_range), 'r--', alpha=0.7)\n",
        "\n",
        "        axes[1, 0].set_xlabel('Test Samples')\n",
        "        axes[1, 0].set_ylabel('Accuracy')\n",
        "        axes[1, 0].set_title('Sample Size vs Performance Relationship')\n",
        "        axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "        # 5. Performance metrics correlation heatmap\n",
        "        corr_matrix = summary_df[['Accuracy', 'F1Score', 'AUC_ROC', 'Precision', 'Recall']].corr()\n",
        "        im = axes[1, 1].imshow(corr_matrix, cmap='coolwarm', vmin=-1, vmax=1)\n",
        "        axes[1, 1].set_xticks(range(len(corr_matrix.columns)))\n",
        "        axes[1, 1].set_yticks(range(len(corr_matrix.columns)))\n",
        "        axes[1, 1].set_xticklabels(corr_matrix.columns, rotation=45, ha='right')\n",
        "        axes[1, 1].set_yticklabels(corr_matrix.columns)\n",
        "        axes[1, 1].set_title('Performance Metrics Correlation')\n",
        "\n",
        "        # Add values\n",
        "        for i in range(len(corr_matrix.columns)):\n",
        "            for j in range(len(corr_matrix.columns)):\n",
        "                axes[1, 1].text(j, i, f'{corr_matrix.iloc[i, j]:.2f}',\n",
        "                               ha='center', va='center', color='white' if abs(corr_matrix.iloc[i, j]) > 0.5 else 'black')\n",
        "\n",
        "        plt.colorbar(im, ax=axes[1, 1], fraction=0.046, pad=0.04)\n",
        "\n",
        "        # 6. Cross-ecoregion transferability summary\n",
        "        axes[1, 2].axis('off')\n",
        "        summary_text = f\"\"\"\n",
        "Cross-Ecoregion Transferability Analysis Summary:\n",
        "\n",
        "Ecoregions analyzed: {len(summary_df)}\n",
        "Mean Accuracy: {summary_df['Accuracy'].mean():.3f}\n",
        "Accuracy Standard Deviation: {summary_df['Accuracy'].std():.3f}\n",
        "Performance Range: {(summary_df['Accuracy'].max() - summary_df['Accuracy'].min()):.3f}\n",
        "\n",
        "Assessment Conclusions:\n",
        "\"\"\"\n",
        "\n",
        "        if summary_df['Accuracy'].std() > 0.1:\n",
        "            summary_text += \"\"\"\n",
        "• Limited cross-ecoregion transferability\n",
        "• Some ecoregions have unique characteristics that are difficult to transfer\n",
        "• Recommendation: Use ecoregion-stratified modeling strategy\n",
        "\"\"\"\n",
        "        else:\n",
        "            summary_text += \"\"\"\n",
        "• Good cross-ecoregion transferability\n",
        "• Small performance differences across ecoregions\n",
        "• Ecoregion-stratified modeling still valuable but not essential\n",
        "\"\"\"\n",
        "\n",
        "        axes[1, 2].text(0.1, 0.5, summary_text, transform=axes[1, 2].transAxes,\n",
        "                       fontsize=11, verticalalignment='center',\n",
        "                       bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
        "\n",
        "        plt.suptitle('Leave-One-Ecoregion Cross-Validation Comprehensive Analysis', fontsize=16, fontweight='bold')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "# Execute leave-one-ecoregion validation\n",
        "print(\"\\nStarting leave-one-ecoregion cross-validation...\")\n",
        "validator = LeaveOneEcoregionOutValidator()\n",
        "results = validator.validate(df, available_features)\n",
        "\n",
        "# Analyze results\n",
        "summary_df = validator.analyze_results(results)\n",
        "\n",
        "# Generate final report\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Leave-One-Ecoregion Validation Final Report\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"\\nKey Findings:\")\n",
        "if summary_df['Accuracy'].std() > 0.1:\n",
        "    print(\"⚠ Limited cross-ecoregion transferability:\")\n",
        "    print(f\"  Accuracy standard deviation across ecoregions: {summary_df['Accuracy'].std():.3f}\")\n",
        "    print(f\"  Maximum performance difference: {(summary_df['Accuracy'].max() - summary_df['Accuracy'].min()):.3f}\")\n",
        "    print(\"  This supports the need for ecoregion-stratified modeling\")\n",
        "else:\n",
        "    print(\"✓ Good cross-ecoregion transferability:\")\n",
        "    print(f\"  Accuracy standard deviation across ecoregions: {summary_df['Accuracy'].std():.3f}\")\n",
        "    print(\"  Model shows consistent performance across different ecoregions\")\n",
        "\n",
        "print(f\"\\nManuscript Revision Suggestions:\")\n",
        "print(\"1. Add experimental design of leave-one-ecoregion validation in Methods section\")\n",
        "print(\"2. Report cross-ecoregion validation performance metrics in Results section\")\n",
        "print(\"3. Analyze limitations of cross-ecoregion transferability in Discussion section\")\n",
        "print(\"4. Justify the necessity of ecoregion-stratified modeling\")\n",
        "\n",
        "# Save results\n",
        "import json\n",
        "import os\n",
        "os.makedirs('leave_one_out_results', exist_ok=True)\n",
        "\n",
        "# Save only serializable data\n",
        "save_results = {}\n",
        "for region, result in results.items():\n",
        "    save_results[region] = {\n",
        "        'metrics': result['metrics'],\n",
        "        'train_samples': result['train_samples'],\n",
        "        'test_samples': result['test_samples'],\n",
        "        'train_regions': result['train_regions']\n",
        "    }\n",
        "\n",
        "with open('leave_one_out_results/leave_one_out_results.json', 'w') as f:\n",
        "    json.dump(save_results, f, indent=2)\n",
        "\n",
        "summary_df.to_csv('leave_one_out_results/leave_one_out_summary.csv', index=False)\n",
        "print(\"\\n✓ Leave-one-out validation results saved:\")\n",
        "print(\"  - leave_one_out_results/leave_one_out_results.json\")\n",
        "print(\"  - leave_one_out_results/leave_one_out_summary.csv\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Leave-One-Ecoregion Cross-Validation Completed!\")\n",
        "print(\"=\"*60)"
      ]
    }
  ]
}