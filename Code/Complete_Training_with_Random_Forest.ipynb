{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EuONoImcQf85"
      },
      "outputs": [],
      "source": [
        "# ==================== Section 5: Complete Training with Random Forest ====================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (accuracy_score, f1_score, roc_auc_score,\n",
        "                           confusion_matrix, precision_score, recall_score,\n",
        "                           cohen_kappa_score, matthews_corrcoef, roc_curve,\n",
        "                           precision_recall_curve, average_precision_score)\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import RFECV\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import os\n",
        "import joblib\n",
        "import json\n",
        "\n",
        "print(\"Complete Training with Random Forest - ECF-TST vs Global Model\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# ==================== 1. Load and Process Real Data ====================\n",
        "print(\"Step 1: Loading and processing real data...\")\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_path = '/content/drive/MyDrive/merged_data_by_year).csv'\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(data_path)\n",
        "print(f\"Data loaded successfully: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
        "\n",
        "# Display basic information\n",
        "print(\"\\nData basic information:\")\n",
        "print(df.info())\n",
        "\n",
        "# Check for missing values\n",
        "print(\"\\nChecking for missing values...\")\n",
        "missing_counts = df.isnull().sum()\n",
        "missing_pct = (missing_counts / len(df)) * 100\n",
        "missing_summary = pd.DataFrame({\n",
        "    'Missing Count': missing_counts,\n",
        "    'Missing Percentage': missing_pct\n",
        "})\n",
        "\n",
        "# Show only columns with missing values\n",
        "missing_summary = missing_summary[missing_summary['Missing Count'] > 0]\n",
        "if not missing_summary.empty:\n",
        "    print(\"Columns with missing values:\")\n",
        "    print(missing_summary)\n",
        "else:\n",
        "    print(\"No missing values found\")\n",
        "\n",
        "# Handle missing values: DELETE rows with missing values\n",
        "print(\"\\nHandling missing values...\")\n",
        "original_shape = df.shape\n",
        "df = df.dropna()\n",
        "rows_removed = original_shape[0] - df.shape[0]\n",
        "print(f\"  Rows with missing values removed: {rows_removed}\")\n",
        "print(f\"  New data shape: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
        "\n",
        "# Check class distribution\n",
        "print(\"\\nChecking class distribution...\")\n",
        "class_dist = df['b1'].value_counts()\n",
        "print(f\"Class distribution (b1):\")\n",
        "print(class_dist)\n",
        "print(f\"Class ratio (0:stable / 1:disturbance): {class_dist[0]/len(df)*100:.1f}% / {class_dist[1]/len(df)*100:.1f}%\")\n",
        "\n",
        "# Check ecoregion distribution\n",
        "print(\"\\nChecking ecoregion distribution...\")\n",
        "ecoregion_counts = df['ID'].value_counts()\n",
        "print(f\"Total ecoregions: {len(ecoregion_counts)}\")\n",
        "print(\"\\nTop 10 ecoregions by sample count:\")\n",
        "print(ecoregion_counts.head(10))\n",
        "\n",
        "# ==================== 2. Define Complete Feature Set ====================\n",
        "print(\"\\nStep 2: Defining complete feature set...\")\n",
        "\n",
        "# Define feature groups based on paper description\n",
        "feature_groups = {\n",
        "    'Remote Sensing Features': [\n",
        "        'NBR', 'NDVI',\n",
        "        'NBR_con_texture', 'NBR_cor_texture', 'NBR_ent_texture',\n",
        "        'NDVI_con_texture', 'NDVI_cor_texture', 'NDVI_ent_texture',\n",
        "        'NBR_rol_3y_temporal', 'NBR_rol_5y_temporal', 'NBR_vola_5y_temporal',\n",
        "        'NDVI_rol_3y_temporal', 'NDVI_rol_5y_temporal', 'NDVI_vola_5y_temporal'\n",
        "    ],\n",
        "\n",
        "    'Topographic Features': ['aspect', 'elevation', 'slope', 'tpi'],\n",
        "\n",
        "    'Climate Features': [\n",
        "        'annual_precip', 'annual_temp', 'prev_year_precip',\n",
        "        'summer_temp', 'temp_anomaly'\n",
        "    ],\n",
        "\n",
        "    'Socioeconomic Features': ['gdp', 'population'],\n",
        "\n",
        "    'Landcover': ['landcover']\n",
        "}\n",
        "\n",
        "# Combine all features into a single list\n",
        "feature_cols = []\n",
        "for group_name, features in feature_groups.items():\n",
        "    feature_cols.extend(features)\n",
        "    print(f\"  {group_name}: {len(features)} features\")\n",
        "\n",
        "print(f\"\\nTotal: {len(feature_cols)} features\")\n",
        "\n",
        "# Check which features don't exist in the data\n",
        "missing_features = [f for f in feature_cols if f not in df.columns]\n",
        "if missing_features:\n",
        "    print(f\"\\nWarning: The following {len(missing_features)} features are not in the data:\")\n",
        "    for f in missing_features:\n",
        "        print(f\"  - {f}\")\n",
        "\n",
        "    # Remove non-existent features from the feature list\n",
        "    feature_cols = [f for f in feature_cols if f in df.columns]\n",
        "    print(f\"\\nUsing {len(feature_cols)} available features\")\n",
        "else:\n",
        "    print(\"\\n✓ All features exist in the data\")\n",
        "\n",
        "# ==================== 3. Training Class ====================\n",
        "print(\"\\nStep 3: Defining training class...\")\n",
        "\n",
        "class EcoregionModelTrainer:\n",
        "    \"\"\"Ecoregion trainer with Random Forest\"\"\"\n",
        "\n",
        "    def __init__(self, test_size=0.2, random_state=42, n_jobs=-1):\n",
        "        self.test_size = test_size\n",
        "        self.random_state = random_state\n",
        "        self.n_jobs = n_jobs\n",
        "        self.models = {}\n",
        "        self.results = {}\n",
        "        self.summary_df = None\n",
        "        self.global_model = None\n",
        "        self.global_results = {}\n",
        "\n",
        "    def prepare_data(self, df_region, feature_cols, target_col='b1'):\n",
        "        \"\"\"Prepare data for training\"\"\"\n",
        "        X = df_region[feature_cols].copy()\n",
        "        y = df_region[target_col].copy()\n",
        "\n",
        "        # Check and handle any remaining missing values\n",
        "        missing_cols = X.columns[X.isnull().any()].tolist()\n",
        "        if missing_cols:\n",
        "            print(f\"    Handling missing values in {len(missing_cols)} features...\")\n",
        "            for col in missing_cols:\n",
        "                median_val = X[col].median()\n",
        "                X[col].fillna(median_val, inplace=True)\n",
        "\n",
        "        # Standardize features\n",
        "        scaler = StandardScaler()\n",
        "        X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "        return X_scaled, y, scaler, X.columns.tolist()\n",
        "\n",
        "    def calculate_comprehensive_metrics(self, y_true, y_pred, y_pred_proba=None):\n",
        "        \"\"\"Calculate comprehensive evaluation metrics\"\"\"\n",
        "        metrics = {}\n",
        "\n",
        "        # Basic metrics\n",
        "        metrics['accuracy'] = accuracy_score(y_true, y_pred)\n",
        "        metrics['precision'] = precision_score(y_true, y_pred, zero_division=0)\n",
        "        metrics['recall'] = recall_score(y_true, y_pred, zero_division=0)\n",
        "        metrics['f1_score'] = f1_score(y_true, y_pred, zero_division=0)\n",
        "        metrics['kappa'] = cohen_kappa_score(y_true, y_pred)\n",
        "        metrics['mcc'] = matthews_corrcoef(y_true, y_pred)\n",
        "\n",
        "        # AUC-ROC\n",
        "        if y_pred_proba is not None and len(np.unique(y_true)) > 1:\n",
        "            metrics['auc_roc'] = roc_auc_score(y_true, y_pred_proba)\n",
        "            # PR curve related metrics\n",
        "            metrics['average_precision'] = average_precision_score(y_true, y_pred_proba)\n",
        "        else:\n",
        "            metrics['auc_roc'] = 0.5\n",
        "            metrics['average_precision'] = 0.5\n",
        "\n",
        "        # Confusion matrix related metrics\n",
        "        cm = confusion_matrix(y_true, y_pred)\n",
        "        if cm.shape == (2, 2):\n",
        "            TN, FP, FN, TP = cm.ravel()\n",
        "\n",
        "            # Producer's Accuracy = 1 - Omission Error\n",
        "            metrics['pa_stable'] = TN / (TN + FP) if (TN + FP) > 0 else 0  # Stable class\n",
        "            metrics['pa_disturbance'] = TP / (TP + FN) if (TP + FN) > 0 else 0  # Disturbance class\n",
        "\n",
        "            # User's Accuracy = 1 - Commission Error\n",
        "            metrics['ua_stable'] = TN / (TN + FN) if (TN + FN) > 0 else 0  # Stable class\n",
        "            metrics['ua_disturbance'] = TP / (TP + FP) if (TP + FP) > 0 else 0  # Disturbance class\n",
        "\n",
        "            # Omission Error\n",
        "            metrics['oe_stable'] = 1 - metrics['pa_stable'] if 'pa_stable' in metrics else None\n",
        "            metrics['oe_disturbance'] = 1 - metrics['pa_disturbance'] if 'pa_disturbance' in metrics else None\n",
        "\n",
        "            # Commission Error\n",
        "            metrics['ce_stable'] = 1 - metrics['ua_stable'] if 'ua_stable' in metrics else None\n",
        "            metrics['ce_disturbance'] = 1 - metrics['ua_disturbance'] if 'ua_disturbance' in metrics else None\n",
        "\n",
        "            # Mean accuracies\n",
        "            metrics['mean_pa'] = (metrics['pa_stable'] + metrics['pa_disturbance']) / 2\n",
        "            metrics['mean_ua'] = (metrics['ua_stable'] + metrics['ua_disturbance']) / 2\n",
        "\n",
        "            # Balanced accuracy\n",
        "            metrics['balanced_accuracy'] = metrics['mean_pa']\n",
        "\n",
        "            # Add confusion matrix values\n",
        "            metrics['TN'] = TN\n",
        "            metrics['FP'] = FP\n",
        "            metrics['FN'] = FN\n",
        "            metrics['TP'] = TP\n",
        "\n",
        "        return metrics, cm\n",
        "\n",
        "    def train_ecoregion_model(self, df, ecoregion_id, feature_cols):\n",
        "        \"\"\"Train Random Forest model for a single ecoregion\"\"\"\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"ECF-TST Training: Ecoregion {ecoregion_id}\")\n",
        "        print('='*70)\n",
        "\n",
        "        try:\n",
        "            # Filter data for the ecoregion\n",
        "            df_region = df[df['ID'] == ecoregion_id].copy()\n",
        "\n",
        "            print(f\"  Sample count: {len(df_region)}\")\n",
        "            print(f\"  Class distribution: {df_region['b1'].value_counts().to_dict()}\")\n",
        "\n",
        "            # Prepare data\n",
        "            X, y, scaler, feature_names = self.prepare_data(df_region, feature_cols)\n",
        "\n",
        "            # Split data into train and test sets (80/20)\n",
        "            X_train, X_test, y_train, y_test = train_test_split(\n",
        "                X, y, test_size=self.test_size, random_state=self.random_state, stratify=y\n",
        "            )\n",
        "\n",
        "            print(f\"  Training set: {X_train.shape}, Test set: {X_test.shape}\")\n",
        "\n",
        "            # Train Random Forest model (no SMOTE, no feature selection for simplicity)\n",
        "            print(\"    Training Random Forest model...\")\n",
        "            model = RandomForestClassifier(\n",
        "                n_estimators=100,\n",
        "                max_depth=None,\n",
        "                min_samples_split=2,\n",
        "                min_samples_leaf=1,\n",
        "                max_features='sqrt',\n",
        "                random_state=self.random_state,\n",
        "                n_jobs=self.n_jobs,\n",
        "                verbose=0\n",
        "            )\n",
        "\n",
        "            model.fit(X_train, y_train)\n",
        "\n",
        "            # Predict and evaluate\n",
        "            y_pred = model.predict(X_test)\n",
        "            y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "            # Calculate comprehensive metrics\n",
        "            metrics, cm = self.calculate_comprehensive_metrics(y_test, y_pred, y_pred_proba)\n",
        "\n",
        "            print(f\"\\n  Test set performance:\")\n",
        "            print(f\"    Accuracy: {metrics['accuracy']:.4f}\")\n",
        "            print(f\"    F1 Score: {metrics['f1_score']:.4f}\")\n",
        "            print(f\"    AUC-ROC: {metrics['auc_roc']:.4f}\")\n",
        "            print(f\"    Producer's Accuracy (stable): {metrics.get('pa_stable', 0):.4f}\")\n",
        "            print(f\"    Producer's Accuracy (disturbance): {metrics.get('pa_disturbance', 0):.4f}\")\n",
        "\n",
        "            # Save results\n",
        "            result = {\n",
        "                'model': model,\n",
        "                'scaler': scaler,\n",
        "                'metrics': metrics,\n",
        "                'confusion_matrix': cm,\n",
        "                'test_size': len(y_test),\n",
        "                'train_size': len(y_train),\n",
        "                'X_test': X_test,\n",
        "                'y_test': y_test,\n",
        "                'y_pred': y_pred,\n",
        "                'y_pred_proba': y_pred_proba,\n",
        "                'feature_names': feature_names\n",
        "            }\n",
        "\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  Error training ecoregion {ecoregion_id}: {str(e)}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            return None\n",
        "\n",
        "    def train_ecf_tst_models(self, df, feature_cols, min_samples=1000):\n",
        "        \"\"\"Train ECF-TST models for all ecoregions\"\"\"\n",
        "        # Sort ecoregions by sample count\n",
        "        ecoregion_counts = df['ID'].value_counts()\n",
        "\n",
        "        # Filter ecoregions with sufficient samples\n",
        "        eligible_ecoregions = ecoregion_counts[ecoregion_counts >= min_samples].index.tolist()\n",
        "\n",
        "        print(f\"\\nEcoregions meeting minimum sample requirement ({min_samples}): {len(eligible_ecoregions)}\")\n",
        "        print(f\"Training ALL eligible ecoregions...\")\n",
        "\n",
        "        for i, ecoregion_id in enumerate(eligible_ecoregions, 1):\n",
        "            print(f\"\\n{'='*70}\")\n",
        "            print(f\"Progress: {i}/{len(eligible_ecoregions)} - Ecoregion: {ecoregion_id}\")\n",
        "            print(f\"Sample count: {ecoregion_counts[ecoregion_id]}\")\n",
        "            print('='*70)\n",
        "\n",
        "            result = self.train_ecoregion_model(df, ecoregion_id, feature_cols)\n",
        "\n",
        "            if result:\n",
        "                self.models[ecoregion_id] = result['model']\n",
        "                self.results[ecoregion_id] = result\n",
        "                print(f\"✓ Ecoregion {ecoregion_id} training completed\")\n",
        "            else:\n",
        "                print(f\"✗ Ecoregion {ecoregion_id} training failed\")\n",
        "\n",
        "        # Summarize results\n",
        "        if self.results:\n",
        "            self.summarize_ecf_tst_results()\n",
        "\n",
        "        return self.models, self.results\n",
        "\n",
        "    def train_global_model(self, df, feature_cols, test_size=0.2):\n",
        "        \"\"\"Train global model using all data\"\"\"\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"Training Global Model\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "        # Prepare all data\n",
        "        X_all, y_all, scaler, feature_names = self.prepare_data(df, feature_cols)\n",
        "\n",
        "        # Split all data into train and test (80/20)\n",
        "        X_train_all, X_test_all, y_train_all, y_test_all = train_test_split(\n",
        "            X_all, y_all, test_size=test_size, random_state=self.random_state, stratify=y_all\n",
        "        )\n",
        "\n",
        "        print(f\"Global training set: {X_train_all.shape}\")\n",
        "        print(f\"Global test set: {X_test_all.shape}\")\n",
        "        print(f\"Class distribution in training: {np.bincount(y_train_all)}\")\n",
        "\n",
        "        # Train global Random Forest model\n",
        "        print(\"\\nTraining Global Random Forest model...\")\n",
        "        global_model = RandomForestClassifier(\n",
        "            n_estimators=100,\n",
        "            max_depth=None,\n",
        "            min_samples_split=2,\n",
        "            min_samples_leaf=1,\n",
        "            max_features='sqrt',\n",
        "            random_state=self.random_state,\n",
        "            n_jobs=self.n_jobs,\n",
        "            verbose=0\n",
        "        )\n",
        "\n",
        "        global_model.fit(X_train_all, y_train_all)\n",
        "\n",
        "        # Evaluate on global test set\n",
        "        y_pred_all = global_model.predict(X_test_all)\n",
        "        y_pred_proba_all = global_model.predict_proba(X_test_all)[:, 1]\n",
        "\n",
        "        # Calculate comprehensive metrics for global test\n",
        "        global_metrics, global_cm = self.calculate_comprehensive_metrics(y_test_all, y_pred_all, y_pred_proba_all)\n",
        "\n",
        "        print(f\"\\nGlobal model performance on global test set:\")\n",
        "        print(f\"  Accuracy: {global_metrics['accuracy']:.4f}\")\n",
        "        print(f\"  F1 Score: {global_metrics['f1_score']:.4f}\")\n",
        "        print(f\"  AUC-ROC: {global_metrics['auc_roc']:.4f}\")\n",
        "\n",
        "        # Now evaluate global model on each ecoregion's test set\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"Evaluating Global Model on Each Ecoregion's Test Set\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "        # We need to collect each ecoregion's test data\n",
        "        for ecoregion_id, result in self.results.items():\n",
        "            # Get the test data for this ecoregion from ECF-TST training\n",
        "            X_test_eco = result['X_test']\n",
        "            y_test_eco = result['y_test']\n",
        "\n",
        "            # Predict using global model\n",
        "            y_pred_eco = global_model.predict(X_test_eco)\n",
        "            y_pred_proba_eco = global_model.predict_proba(X_test_eco)[:, 1]\n",
        "\n",
        "            # Calculate metrics\n",
        "            eco_metrics, eco_cm = self.calculate_comprehensive_metrics(y_test_eco, y_pred_eco, y_pred_proba_eco)\n",
        "\n",
        "            # Store results\n",
        "            self.global_results[ecoregion_id] = {\n",
        "                'metrics': eco_metrics,\n",
        "                'confusion_matrix': eco_cm,\n",
        "                'test_size': len(y_test_eco)\n",
        "            }\n",
        "\n",
        "            print(f\"\\nEcoregion {ecoregion_id}:\")\n",
        "            print(f\"  Accuracy: {eco_metrics['accuracy']:.4f}\")\n",
        "            print(f\"  F1 Score: {eco_metrics['f1_score']:.4f}\")\n",
        "\n",
        "        # Calculate average performance across all ecoregions\n",
        "        if self.global_results:\n",
        "            accuracies = [r['metrics']['accuracy'] for r in self.global_results.values()]\n",
        "            f1_scores = [r['metrics']['f1_score'] for r in self.global_results.values()]\n",
        "            auc_scores = [r['metrics']['auc_roc'] for r in self.global_results.values()]\n",
        "\n",
        "            print(f\"\\nGlobal model average performance across ecoregions:\")\n",
        "            print(f\"  Mean Accuracy: {np.mean(accuracies):.4f} (±{np.std(accuracies):.4f})\")\n",
        "            print(f\"  Mean F1 Score: {np.mean(f1_scores):.4f} (±{np.std(f1_scores):.4f})\")\n",
        "            print(f\"  Mean AUC-ROC: {np.mean(auc_scores):.4f} (±{np.std(auc_scores):.4f})\")\n",
        "\n",
        "        self.global_model = global_model\n",
        "        return global_model, self.global_results\n",
        "\n",
        "    def summarize_ecf_tst_results(self):\n",
        "        \"\"\"Summarize results from all ecoregions for ECF-TST model\"\"\"\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"Summary of ECF-TST Model Results\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "        summary_data = []\n",
        "        for ecoregion_id, result in self.results.items():\n",
        "            metrics = result['metrics']\n",
        "            summary_data.append({\n",
        "                'EcoregionID': ecoregion_id,\n",
        "                'TrainSamples': result['train_size'],\n",
        "                'TestSamples': result['test_size'],\n",
        "                'Accuracy': metrics['accuracy'],\n",
        "                'F1Score': metrics['f1_score'],\n",
        "                'AUC_ROC': metrics['auc_roc'],\n",
        "                'Kappa': metrics['kappa'],\n",
        "                'MCC': metrics['mcc'],\n",
        "                'PA_Stable': metrics.get('pa_stable', 0),\n",
        "                'PA_Disturbance': metrics.get('pa_disturbance', 0),\n",
        "                'UA_Stable': metrics.get('ua_stable', 0),\n",
        "                'UA_Disturbance': metrics.get('ua_disturbance', 0),\n",
        "                'OE_Stable': metrics.get('oe_stable', 0),\n",
        "                'OE_Disturbance': metrics.get('oe_disturbance', 0),\n",
        "                'CE_Stable': metrics.get('ce_stable', 0),\n",
        "                'CE_Disturbance': metrics.get('ce_disturbance', 0),\n",
        "                'Balanced_Accuracy': metrics.get('balanced_accuracy', 0),\n",
        "                'TN': metrics.get('TN', 0),\n",
        "                'FP': metrics.get('FP', 0),\n",
        "                'FN': metrics.get('FN', 0),\n",
        "                'TP': metrics.get('TP', 0)\n",
        "            })\n",
        "\n",
        "        self.summary_df = pd.DataFrame(summary_data)\n",
        "\n",
        "        print(\"\\nPerformance by Ecoregion:\")\n",
        "        print(self.summary_df[['EcoregionID', 'Accuracy', 'F1Score', 'AUC_ROC', 'Kappa', 'Balanced_Accuracy']].to_string(index=False))\n",
        "\n",
        "        # Statistical analysis\n",
        "        print(f\"\\nStatistical Analysis:\")\n",
        "        print(f\"Mean Accuracy: {self.summary_df['Accuracy'].mean():.4f} (±{self.summary_df['Accuracy'].std():.4f})\")\n",
        "        print(f\"Mean F1 Score: {self.summary_df['F1Score'].mean():.4f} (±{self.summary_df['F1Score'].std():.4f})\")\n",
        "        print(f\"Mean AUC-ROC: {self.summary_df['AUC_ROC'].mean():.4f} (±{self.summary_df['AUC_ROC'].std():.4f})\")\n",
        "        print(f\"Mean Kappa: {self.summary_df['Kappa'].mean():.4f} (±{self.summary_df['Kappa'].std():.4f})\")\n",
        "        print(f\"Mean Balanced Accuracy: {self.summary_df['Balanced_Accuracy'].mean():.4f} (±{self.summary_df['Balanced_Accuracy'].std():.4f})\")\n",
        "\n",
        "        return self.summary_df\n",
        "\n",
        "    def create_table1_comparison(self):\n",
        "        \"\"\"Create Table 1: Comparison between ECF-TST and Global models\"\"\"\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"Table 1: Performance Comparison\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "        # Calculate means and standard deviations for ECF-TST\n",
        "        ecf_mean_accuracy = self.summary_df['Accuracy'].mean()\n",
        "        ecf_std_accuracy = self.summary_df['Accuracy'].std()\n",
        "        ecf_mean_f1 = self.summary_df['F1Score'].mean()\n",
        "        ecf_std_f1 = self.summary_df['F1Score'].std()\n",
        "        ecf_mean_kappa = self.summary_df['Kappa'].mean()\n",
        "        ecf_std_kappa = self.summary_df['Kappa'].std()\n",
        "        ecf_mean_pa = self.summary_df['Balanced_Accuracy'].mean()\n",
        "        ecf_std_pa = self.summary_df['Balanced_Accuracy'].std()\n",
        "\n",
        "        # Calculate means and standard deviations for Global model\n",
        "        if self.global_results:\n",
        "            global_accuracies = [r['metrics']['accuracy'] for r in self.global_results.values()]\n",
        "            global_f1s = [r['metrics']['f1_score'] for r in self.global_results.values()]\n",
        "            global_kappas = [r['metrics']['kappa'] for r in self.global_results.values()]\n",
        "            global_pas = [r['metrics'].get('balanced_accuracy', 0.5) for r in self.global_results.values()]\n",
        "\n",
        "            global_mean_accuracy = np.mean(global_accuracies)\n",
        "            global_std_accuracy = np.std(global_accuracies)\n",
        "            global_mean_f1 = np.mean(global_f1s)\n",
        "            global_std_f1 = np.std(global_f1s)\n",
        "            global_mean_kappa = np.mean(global_kappas)\n",
        "            global_std_kappa = np.std(global_kappas)\n",
        "            global_mean_pa = np.mean(global_pas)\n",
        "            global_std_pa = np.std(global_pas)\n",
        "\n",
        "            # Calculate differences\n",
        "            diff_accuracy = ecf_mean_accuracy - global_mean_accuracy\n",
        "            diff_f1 = ecf_mean_f1 - global_mean_f1\n",
        "            diff_kappa = ecf_mean_kappa - global_mean_kappa\n",
        "            diff_pa = ecf_mean_pa - global_mean_pa\n",
        "\n",
        "            # Create Table 1\n",
        "            table1 = pd.DataFrame({\n",
        "                'Metric': ['Overall Accuracy (OA)', 'F1 Score', \"Cohen's Kappa\", 'Balanced Accuracy (Producer\\'s)'],\n",
        "                'ECF-TST Model': [\n",
        "                    f'{ecf_mean_accuracy:.3f} (±{ecf_std_accuracy:.3f})',\n",
        "                    f'{ecf_mean_f1:.3f} (±{ecf_std_f1:.3f})',\n",
        "                    f'{ecf_mean_kappa:.3f} (±{ecf_std_kappa:.3f})',\n",
        "                    f'{ecf_mean_pa:.3f} (±{ecf_std_pa:.3f})'\n",
        "                ],\n",
        "                'Global Model': [\n",
        "                    f'{global_mean_accuracy:.3f} (±{global_std_accuracy:.3f})',\n",
        "                    f'{global_mean_f1:.3f} (±{global_std_f1:.3f})',\n",
        "                    f'{global_mean_kappa:.3f} (±{global_std_kappa:.3f})',\n",
        "                    f'{global_mean_pa:.3f} (±{global_std_pa:.3f})'\n",
        "                ],\n",
        "                'Improvement': [\n",
        "                    f'+{diff_accuracy:.3f}',\n",
        "                    f'+{diff_f1:.3f}',\n",
        "                    f'+{diff_kappa:.3f}',\n",
        "                    f'+{diff_pa:.3f}'\n",
        "                ]\n",
        "            })\n",
        "\n",
        "            print(\"\\nTable 1: Performance comparison between ECF-TST and Global models\")\n",
        "            print(table1.to_string(index=False))\n",
        "\n",
        "            return table1\n",
        "\n",
        "        return None\n",
        "\n",
        "    def export_supplementary_tables(self, output_path='/content/drive/MyDrive/ECF_TST_Results'):\n",
        "        \"\"\"Export all supplementary tables\"\"\"\n",
        "        import os\n",
        "        os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "        print(f\"\\nExporting supplementary tables to: {output_path}\")\n",
        "\n",
        "        # 1. Supplementary Table S3: ECF-TST完整混淆矩阵汇总表（各生态区）\n",
        "        if self.summary_df is not None:\n",
        "            table_s3 = self.summary_df[['EcoregionID', 'TN', 'FP', 'FN', 'TP',\n",
        "                                       'PA_Stable', 'PA_Disturbance',\n",
        "                                       'UA_Stable', 'UA_Disturbance',\n",
        "                                       'OE_Stable', 'OE_Disturbance',\n",
        "                                       'CE_Stable', 'CE_Disturbance']].copy()\n",
        "            table_s3_path = f'{output_path}/Supplementary_Table_S3_ECF_TST_Confusion_Matrix.csv'\n",
        "            table_s3.to_csv(table_s3_path, index=False, encoding='utf-8-sig')\n",
        "            print(f\"✓ Supplementary Table S3 saved: {table_s3_path}\")\n",
        "\n",
        "        # 2. Supplementary Table S4: 全局模型完整混淆矩阵汇总表（各生态区）\n",
        "        if self.global_results:\n",
        "            global_confusion_data = []\n",
        "            for ecoregion_id, result in self.global_results.items():\n",
        "                metrics = result['metrics']\n",
        "                cm = result['confusion_matrix']\n",
        "\n",
        "                if cm.shape == (2, 2):\n",
        "                    TN, FP, FN, TP = cm.ravel()\n",
        "                else:\n",
        "                    TN, FP, FN, TP = 0, 0, 0, 0\n",
        "\n",
        "                global_confusion_data.append({\n",
        "                    'EcoregionID': ecoregion_id,\n",
        "                    'TN': TN,\n",
        "                    'FP': FP,\n",
        "                    'FN': FN,\n",
        "                    'TP': TP,\n",
        "                    'PA_Stable': metrics.get('pa_stable', 0),\n",
        "                    'PA_Disturbance': metrics.get('pa_disturbance', 0),\n",
        "                    'UA_Stable': metrics.get('ua_stable', 0),\n",
        "                    'UA_Disturbance': metrics.get('ua_disturbance', 0),\n",
        "                    'OE_Stable': metrics.get('oe_stable', 0),\n",
        "                    'OE_Disturbance': metrics.get('oe_disturbance', 0),\n",
        "                    'CE_Stable': metrics.get('ce_stable', 0),\n",
        "                    'CE_Disturbance': metrics.get('ce_disturbance', 0)\n",
        "                })\n",
        "\n",
        "            table_s4 = pd.DataFrame(global_confusion_data)\n",
        "            table_s4_path = f'{output_path}/Supplementary_Table_S4_Global_Confusion_Matrix.csv'\n",
        "            table_s4.to_csv(table_s4_path, index=False, encoding='utf-8-sig')\n",
        "            print(f\"✓ Supplementary Table S4 saved: {table_s4_path}\")\n",
        "\n",
        "        # 3. Supplementary Table S5: 各生态区详细精度指标表（ECF-TST模型）\n",
        "        if self.summary_df is not None:\n",
        "            table_s5 = self.summary_df[['EcoregionID', 'Accuracy', 'F1Score', 'AUC_ROC', 'Kappa', 'MCC',\n",
        "                                       'PA_Stable', 'PA_Disturbance', 'UA_Stable', 'UA_Disturbance',\n",
        "                                       'Balanced_Accuracy', 'TestSamples']].copy()\n",
        "            table_s5_path = f'{output_path}/Supplementary_Table_S5_ECF_TST_Detailed_Metrics.csv'\n",
        "            table_s5.to_csv(table_s5_path, index=False, encoding='utf-8-sig')\n",
        "            print(f\"✓ Supplementary Table S5 saved: {table_s5_path}\")\n",
        "\n",
        "        # 4. Supplementary Table S6: 各生态区详细精度指标表（全局模型）\n",
        "        if self.global_results:\n",
        "            global_metrics_data = []\n",
        "            for ecoregion_id, result in self.global_results.items():\n",
        "                metrics = result['metrics']\n",
        "                global_metrics_data.append({\n",
        "                    'EcoregionID': ecoregion_id,\n",
        "                    'Accuracy': metrics['accuracy'],\n",
        "                    'F1Score': metrics['f1_score'],\n",
        "                    'AUC_ROC': metrics['auc_roc'],\n",
        "                    'Kappa': metrics['kappa'],\n",
        "                    'MCC': metrics['mcc'],\n",
        "                    'PA_Stable': metrics.get('pa_stable', 0),\n",
        "                    'PA_Disturbance': metrics.get('pa_disturbance', 0),\n",
        "                    'UA_Stable': metrics.get('ua_stable', 0),\n",
        "                    'UA_Disturbance': metrics.get('ua_disturbance', 0),\n",
        "                    'Balanced_Accuracy': metrics.get('balanced_accuracy', 0),\n",
        "                    'TestSamples': result['test_size']\n",
        "                })\n",
        "\n",
        "            table_s6 = pd.DataFrame(global_metrics_data)\n",
        "            table_s6_path = f'{output_path}/Supplementary_Table_S6_Global_Detailed_Metrics.csv'\n",
        "            table_s6.to_csv(table_s6_path, index=False, encoding='utf-8-sig')\n",
        "            print(f\"✓ Supplementary Table S6 saved: {table_s6_path}\")\n",
        "\n",
        "        print(f\"\\nAll supplementary tables exported successfully!\")\n",
        "\n",
        "# ==================== 4. Execute Training ====================\n",
        "print(\"\\nStep 4: Executing complete training...\")\n",
        "\n",
        "# Create trainer\n",
        "trainer = EcoregionModelTrainer(\n",
        "    test_size=0.2,  # 80% training, 20% testing\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Train ECF-TST models (separate model for each ecoregion)\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Training ECF-TST Models (Ecoregion-specific)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "ecf_tst_models, ecf_tst_results = trainer.train_ecf_tst_models(\n",
        "    df,\n",
        "    feature_cols,\n",
        "    min_samples=1000  # Minimum samples required for training\n",
        ")\n",
        "\n",
        "# Train Global model and evaluate on each ecoregion\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Training and Evaluating Global Model\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "global_model, global_results = trainer.train_global_model(\n",
        "    df,\n",
        "    feature_cols,\n",
        "    test_size=0.2\n",
        ")\n",
        "\n",
        "# ==================== 5. Generate Final Results ====================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Final Results Summary\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Create Table 1\n",
        "table1 = trainer.create_table1_comparison()\n",
        "\n",
        "# Export supplementary tables\n",
        "output_path = '/content/drive/MyDrive/ECF_TST_Results_Revised'\n",
        "trainer.export_supplementary_tables(output_path)\n",
        "\n",
        "# Summary statistics\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Key Findings Summary\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "if trainer.summary_df is not None and trainer.global_results:\n",
        "    # ECF-TST performance\n",
        "    ecf_acc_mean = trainer.summary_df['Accuracy'].mean()\n",
        "    ecf_acc_std = trainer.summary_df['Accuracy'].std()\n",
        "    ecf_f1_mean = trainer.summary_df['F1Score'].mean()\n",
        "    ecf_f1_std = trainer.summary_df['F1Score'].std()\n",
        "\n",
        "    # Global model performance\n",
        "    global_acc_values = [r['metrics']['accuracy'] for r in trainer.global_results.values()]\n",
        "    global_f1_values = [r['metrics']['f1_score'] for r in trainer.global_results.values()]\n",
        "\n",
        "    global_acc_mean = np.mean(global_acc_values)\n",
        "    global_acc_std = np.std(global_acc_values)\n",
        "    global_f1_mean = np.mean(global_f1_values)\n",
        "    global_f1_std = np.std(global_f1_values)\n",
        "\n",
        "    print(f\"\\nECF-TST Framework Performance:\")\n",
        "    print(f\"  • Mean Accuracy: {ecf_acc_mean:.3f} (±{ecf_acc_std:.3f})\")\n",
        "    print(f\"  • Mean F1 Score: {ecf_f1_mean:.3f} (±{ecf_f1_std:.3f})\")\n",
        "    print(f\"  • Trained Ecoregions: {len(trainer.results)}\")\n",
        "\n",
        "    print(f\"\\nGlobal Model Performance:\")\n",
        "    print(f\"  • Mean Accuracy: {global_acc_mean:.3f} (±{global_acc_std:.3f})\")\n",
        "    print(f\"  • Mean F1 Score: {global_f1_mean:.3f} (±{global_f1_std:.3f})\")\n",
        "\n",
        "    print(f\"\\nECF-TST Improvement over Global Model:\")\n",
        "    print(f\"  • Accuracy Improvement: +{(ecf_acc_mean - global_acc_mean):.3f}\")\n",
        "    print(f\"  • F1 Score Improvement: +{(ecf_f1_mean - global_f1_mean):.3f}\")\n",
        "\n",
        "    # Calculate percentage improvement\n",
        "    acc_improvement_pct = ((ecf_acc_mean - global_acc_mean) / global_acc_mean) * 100\n",
        "    f1_improvement_pct = ((ecf_f1_mean - global_f1_mean) / global_f1_mean) * 100\n",
        "\n",
        "    print(f\"  • Accuracy Improvement (%): +{acc_improvement_pct:.1f}%\")\n",
        "    print(f\"  • F1 Score Improvement (%): +{f1_improvement_pct:.1f}%\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Training Completed Successfully!\")\n",
        "print(\"=\"*80)\n",
        "print(\"\\nGenerated output files:\")\n",
        "print(f\"1. Table 1 (printed above)\")\n",
        "print(f\"2. Supplementary Table S3: ECF-TST Confusion Matrix Summary\")\n",
        "print(f\"3. Supplementary Table S4: Global Model Confusion Matrix Summary\")\n",
        "print(f\"4. Supplementary Table S5: ECF-TST Detailed Metrics\")\n",
        "print(f\"5. Supplementary Table S6: Global Model Detailed Metrics\")\n",
        "print(f\"\\nAll files saved to: {output_path}\")"
      ]
    }
  ]
}