{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EuONoImcQf85"
      },
      "outputs": [],
      "source": [
        "# ==================== Part 2: Spatial Cross-Validation ====================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import xgboost as xgb\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Install necessary libraries\n",
        "!pip install -q scikit-learn xgboost\n",
        "\n",
        "print(\"Spatial Cross-Validation Analysis\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Load real data\n",
        "print(\"Loading real data...\")\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    data_path = '/content/drive/MyDrive/merged_data_by_year).csv'\n",
        "    df = pd.read_csv(data_path)\n",
        "    print(f\"Data loaded successfully: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
        "\n",
        "    # Handle missing values: DELETE rows with missing values\n",
        "    print(\"\\nHandling missing values...\")\n",
        "    original_shape = df.shape\n",
        "    df = df.dropna()\n",
        "    rows_removed = original_shape[0] - df.shape[0]\n",
        "    print(f\"  Rows with missing values removed: {rows_removed}\")\n",
        "    print(f\"  New data shape: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error loading real data: {e}\")\n",
        "    # Use sample data for demonstration\n",
        "    print(\"Using sample data for demonstration...\")\n",
        "    np.random.seed(42)\n",
        "    n_samples = 1000\n",
        "\n",
        "    data = {\n",
        "        'lat': np.random.uniform(30, 50, n_samples),\n",
        "        'lon': np.random.uniform(100, 130, n_samples),\n",
        "        'NBR': np.random.uniform(500, 800, n_samples),\n",
        "        'NDVI': np.random.uniform(600, 900, n_samples),\n",
        "        'aspect': np.random.uniform(0, 360, n_samples),\n",
        "        'elevation': np.random.randint(0, 2000, n_samples),\n",
        "        'slope': np.random.uniform(0, 30, n_samples),\n",
        "        'annual_precip': np.random.uniform(10, 20, n_samples),\n",
        "        'annual_temp': np.random.uniform(-5, 5, n_samples),\n",
        "        'b1': np.random.choice([0, 1], n_samples, p=[0.7, 0.3])\n",
        "    }\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "# Data preprocessing\n",
        "print(\"\\nData preprocessing...\")\n",
        "\n",
        "# Select features (excluding NBR_temporal and NDVI_temporal)\n",
        "feature_cols = ['NBR', 'NDVI', 'aspect', 'elevation', 'slope', 'annual_precip', 'annual_temp']\n",
        "\n",
        "# Ensure features exist in dataframe\n",
        "available_features = [f for f in feature_cols if f in df.columns]\n",
        "print(f\"Using {len(available_features)} available features: {available_features}\")\n",
        "\n",
        "X = df[available_features].values\n",
        "y = df['b1'].values\n",
        "\n",
        "# Check for coordinates\n",
        "if 'lat' in df.columns and 'lon' in df.columns:\n",
        "    coords = df[['lat', 'lon']].values\n",
        "    print(f\"Using spatial coordinates for cross-validation\")\n",
        "else:\n",
        "    print(\"Warning: No spatial coordinates found, creating random coordinates for demonstration\")\n",
        "    np.random.seed(42)\n",
        "    coords = np.random.randn(len(df), 2)\n",
        "    coords[:, 0] = coords[:, 0] * 10 + 45  # Simulate latitude\n",
        "    coords[:, 1] = coords[:, 1] * 10 + 115  # Simulate longitude\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "print(f\"\\nFeature shape: {X_scaled.shape}\")\n",
        "print(f\"Label shape: {y.shape}\")\n",
        "print(f\"Class distribution: Stable={sum(y==0)}, Disturbance={sum(y==1)}\")\n",
        "\n",
        "class SpatialCrossValidator:\n",
        "    \"\"\"Spatial Cross-Validator\"\"\"\n",
        "\n",
        "    def __init__(self, n_splits=5, spatial_strategy='blocks'):\n",
        "        self.n_splits = n_splits\n",
        "        self.spatial_strategy = spatial_strategy\n",
        "\n",
        "    def create_spatial_folds(self, coords):\n",
        "        \"\"\"Create spatial blocks for cross-validation\"\"\"\n",
        "        # Create spatial blocks based on coordinates\n",
        "        lat_min, lat_max = coords[:, 0].min(), coords[:, 0].max()\n",
        "        lon_min, lon_max = coords[:, 1].min(), coords[:, 1].max()\n",
        "\n",
        "        # Create grid\n",
        "        lat_bins = np.linspace(lat_min, lat_max, self.n_splits + 1)\n",
        "        lon_bins = np.linspace(lon_min, lon_max, self.n_splits + 1)\n",
        "\n",
        "        # Assign each point to a spatial block\n",
        "        fold_assignments = np.zeros(len(coords), dtype=int)\n",
        "\n",
        "        for i in range(self.n_splits):\n",
        "            for j in range(self.n_splits):\n",
        "                # Define current block boundaries\n",
        "                lat_left = lat_bins[i]\n",
        "                lat_right = lat_bins[i + 1]\n",
        "                lon_bottom = lon_bins[j]\n",
        "                lon_top = lon_bins[j + 1]\n",
        "\n",
        "                # Find points within current block\n",
        "                in_block = (coords[:, 0] >= lat_left) & \\\n",
        "                          (coords[:, 0] < lat_right) & \\\n",
        "                          (coords[:, 1] >= lon_bottom) & \\\n",
        "                          (coords[:, 1] < lon_top)\n",
        "\n",
        "                # Assign block ID\n",
        "                block_idx = i * self.n_splits + j\n",
        "                if block_idx < self.n_splits:\n",
        "                    fold_assignments[in_block] = block_idx\n",
        "\n",
        "        # For unassigned samples, use K-means clustering\n",
        "        from sklearn.cluster import KMeans\n",
        "        unassigned = fold_assignments == 0\n",
        "        if unassigned.sum() > 0:\n",
        "            kmeans = KMeans(n_clusters=self.n_splits, random_state=42)\n",
        "            clusters = kmeans.fit_predict(coords[unassigned])\n",
        "            fold_assignments[unassigned] = clusters\n",
        "\n",
        "        return fold_assignments\n",
        "\n",
        "    def split(self, X, y, coords):\n",
        "        \"\"\"Generate spatial cross-validation splits\"\"\"\n",
        "        fold_indices = self.create_spatial_folds(coords)\n",
        "\n",
        "        for fold in range(self.n_splits):\n",
        "            train_idx = np.where(fold_indices != fold)[0]\n",
        "            test_idx = np.where(fold_indices == fold)[0]\n",
        "\n",
        "            # Ensure both train and test sets have samples\n",
        "            if len(train_idx) > 0 and len(test_idx) > 0:\n",
        "                yield train_idx, test_idx\n",
        "\n",
        "    def evaluate(self, model, X, y, coords):\n",
        "        \"\"\"Evaluate model performance with spatial cross-validation\"\"\"\n",
        "        spatial_scores = []\n",
        "        fold_details = []\n",
        "\n",
        "        print(f\"\\nStarting {self.n_splits}-fold spatial cross-validation...\")\n",
        "\n",
        "        for fold, (train_idx, test_idx) in enumerate(self.split(X, y, coords)):\n",
        "            print(f\"\\nFold {fold+1}/{self.n_splits}:\")\n",
        "            print(f\"  Training samples: {len(train_idx)}, Test samples: {len(test_idx)}\")\n",
        "\n",
        "            # Split data\n",
        "            X_train, X_test = X[train_idx], X[test_idx]\n",
        "            y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "            # Train model\n",
        "            model.fit(X_train, y_train)\n",
        "\n",
        "            # Predict\n",
        "            y_pred = model.predict(X_test)\n",
        "            y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
        "\n",
        "            # Calculate metrics\n",
        "            accuracy = accuracy_score(y_test, y_pred)\n",
        "            f1 = f1_score(y_test, y_pred, zero_division=0)\n",
        "\n",
        "            if y_pred_proba is not None and len(np.unique(y_test)) > 1:\n",
        "                auc = roc_auc_score(y_test, y_pred_proba)\n",
        "            else:\n",
        "                auc = 0.5\n",
        "\n",
        "            spatial_scores.append({\n",
        "                'fold': fold + 1,\n",
        "                'accuracy': accuracy,\n",
        "                'f1_score': f1,\n",
        "                'auc_roc': auc,\n",
        "                'train_samples': len(train_idx),\n",
        "                'test_samples': len(test_idx)\n",
        "            })\n",
        "\n",
        "            fold_details.append({\n",
        "                'train_idx': train_idx,\n",
        "                'test_idx': test_idx,\n",
        "                'y_test': y_test,\n",
        "                'y_pred': y_pred,\n",
        "                'y_pred_proba': y_pred_proba\n",
        "            })\n",
        "\n",
        "            print(f\"  Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}, AUC-ROC: {auc:.4f}\")\n",
        "\n",
        "        return spatial_scores, fold_details\n",
        "\n",
        "    def compare_with_random_cv(self, model, X, y, coords):\n",
        "        \"\"\"Compare spatial CV with random CV\"\"\"\n",
        "        from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"Spatial CV vs Random CV Comparison\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        # Spatial CV\n",
        "        print(\"\\n1. Spatial Cross-Validation:\")\n",
        "        spatial_scores, _ = self.evaluate(model, X, y, coords)\n",
        "\n",
        "        # Random CV\n",
        "        print(\"\\n2. Random Cross-Validation:\")\n",
        "        random_scores = []\n",
        "        random_cv = StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "        for fold, (train_idx, test_idx) in enumerate(random_cv.split(X, y)):\n",
        "            X_train, X_test = X[train_idx], X[test_idx]\n",
        "            y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "            model.fit(X_train, y_train)\n",
        "            y_pred = model.predict(X_test)\n",
        "\n",
        "            accuracy = accuracy_score(y_test, y_pred)\n",
        "            f1 = f1_score(y_test, y_pred, zero_division=0)\n",
        "\n",
        "            random_scores.append({\n",
        "                'fold': fold + 1,\n",
        "                'accuracy': accuracy,\n",
        "                'f1_score': f1,\n",
        "                'train_samples': len(train_idx),\n",
        "                'test_samples': len(test_idx)\n",
        "            })\n",
        "\n",
        "            print(f\"  Fold {fold+1}: Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "        # Compare results\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"Performance Comparison\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        spatial_acc_mean = np.mean([s['accuracy'] for s in spatial_scores])\n",
        "        spatial_f1_mean = np.mean([s['f1_score'] for s in spatial_scores])\n",
        "        spatial_acc_std = np.std([s['accuracy'] for s in spatial_scores])\n",
        "        spatial_f1_std = np.std([s['f1_score'] for s in spatial_scores])\n",
        "\n",
        "        random_acc_mean = np.mean([s['accuracy'] for s in random_scores])\n",
        "        random_f1_mean = np.mean([s['f1_score'] for s in random_scores])\n",
        "        random_acc_std = np.std([s['accuracy'] for s in random_scores])\n",
        "        random_f1_std = np.std([s['f1_score'] for s in random_scores])\n",
        "\n",
        "        print(f\"\\nSpatial CV:\")\n",
        "        print(f\"  Mean Accuracy: {spatial_acc_mean:.4f} (±{spatial_acc_std:.4f})\")\n",
        "        print(f\"  Mean F1 Score: {spatial_f1_mean:.4f} (±{spatial_f1_std:.4f})\")\n",
        "\n",
        "        print(f\"\\nRandom CV:\")\n",
        "        print(f\"  Mean Accuracy: {random_acc_mean:.4f} (±{random_acc_std:.4f})\")\n",
        "        print(f\"  Mean F1 Score: {random_f1_mean:.4f} (±{random_f1_std:.4f})\")\n",
        "\n",
        "        print(f\"\\nPerformance Difference:\")\n",
        "        print(f\"  Accuracy reduction: {(random_acc_mean - spatial_acc_mean):.4f}\")\n",
        "        print(f\"  F1 Score reduction: {(random_f1_mean - spatial_f1_mean):.4f}\")\n",
        "\n",
        "        # Visualize comparison\n",
        "        self.plot_comparison(spatial_scores, random_scores)\n",
        "\n",
        "        return {\n",
        "            'spatial_scores': spatial_scores,\n",
        "            'random_scores': random_scores,\n",
        "            'spatial_mean_acc': spatial_acc_mean,\n",
        "            'spatial_mean_f1': spatial_f1_mean,\n",
        "            'random_mean_acc': random_acc_mean,\n",
        "            'random_mean_f1': random_f1_mean\n",
        "        }\n",
        "\n",
        "    def plot_comparison(self, spatial_scores, random_scores):\n",
        "        \"\"\"Plot comparison visualization\"\"\"\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "        # 1. Accuracy comparison\n",
        "        spatial_acc = [s['accuracy'] for s in spatial_scores]\n",
        "        random_acc = [s['accuracy'] for s in random_scores]\n",
        "\n",
        "        x = np.arange(len(spatial_acc))\n",
        "        width = 0.35\n",
        "\n",
        "        axes[0, 0].bar(x - width/2, spatial_acc, width, label='Spatial CV', alpha=0.8)\n",
        "        axes[0, 0].bar(x + width/2, random_acc, width, label='Random CV', alpha=0.8)\n",
        "        axes[0, 0].set_xlabel('Fold')\n",
        "        axes[0, 0].set_ylabel('Accuracy')\n",
        "        axes[0, 0].set_title('Accuracy Comparison by Fold')\n",
        "        axes[0, 0].set_xticks(x)\n",
        "        axes[0, 0].set_xticklabels([f'Fold {i+1}' for i in range(len(spatial_acc))])\n",
        "        axes[0, 0].legend()\n",
        "        axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "        # 2. F1 Score comparison\n",
        "        spatial_f1 = [s['f1_score'] for s in spatial_scores]\n",
        "        random_f1 = [s['f1_score'] for s in random_scores]\n",
        "\n",
        "        axes[0, 1].bar(x - width/2, spatial_f1, width, label='Spatial CV', alpha=0.8)\n",
        "        axes[0, 1].bar(x + width/2, random_f1, width, label='Random CV', alpha=0.8)\n",
        "        axes[0, 1].set_xlabel('Fold')\n",
        "        axes[0, 1].set_ylabel('F1 Score')\n",
        "        axes[0, 1].set_title('F1 Score Comparison by Fold')\n",
        "        axes[0, 1].set_xticks(x)\n",
        "        axes[0, 1].set_xticklabels([f'Fold {i+1}' for i in range(len(spatial_f1))])\n",
        "        axes[0, 1].legend()\n",
        "        axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "        # 3. Mean comparison\n",
        "        metrics = ['Accuracy', 'F1 Score']\n",
        "        spatial_means = [np.mean(spatial_acc), np.mean(spatial_f1)]\n",
        "        random_means = [np.mean(random_acc), np.mean(random_f1)]\n",
        "\n",
        "        x2 = np.arange(len(metrics))\n",
        "        axes[1, 0].bar(x2 - width/2, spatial_means, width, label='Spatial CV', alpha=0.8)\n",
        "        axes[1, 0].bar(x2 + width/2, random_means, width, label='Random CV', alpha=0.8)\n",
        "        axes[1, 0].set_xlabel('Metric')\n",
        "        axes[1, 0].set_ylabel('Mean Value')\n",
        "        axes[1, 0].set_title('Mean Performance Comparison')\n",
        "        axes[1, 0].set_xticks(x2)\n",
        "        axes[1, 0].set_xticklabels(metrics)\n",
        "        axes[1, 0].legend()\n",
        "        axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "        # 4. Performance reduction analysis\n",
        "        acc_drop = random_means[0] - spatial_means[0]\n",
        "        f1_drop = random_means[1] - spatial_means[1]\n",
        "\n",
        "        drops = [acc_drop, f1_drop]\n",
        "        colors = ['red' if d > 0 else 'green' for d in drops]\n",
        "\n",
        "        axes[1, 1].bar(metrics, drops, color=colors, alpha=0.8)\n",
        "        axes[1, 1].axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
        "        axes[1, 1].set_xlabel('Metric')\n",
        "        axes[1, 1].set_ylabel('Performance Difference (Random CV - Spatial CV)')\n",
        "        axes[1, 1].set_title('Performance Overestimation due to Spatial Autocorrelation')\n",
        "        axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "        # Add value labels\n",
        "        for i, v in enumerate(drops):\n",
        "            axes[1, 1].text(i, v + (0.01 if v >= 0 else -0.02), f'{v:.4f}',\n",
        "                           ha='center', va='bottom' if v >= 0 else 'top', fontweight='bold')\n",
        "\n",
        "        plt.suptitle('Spatial Cross-Validation vs Random Cross-Validation', fontsize=16, fontweight='bold')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "# Create model\n",
        "print(\"\\nCreating XGBoost model...\")\n",
        "model = xgb.XGBClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.1,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='logloss'\n",
        ")\n",
        "\n",
        "# Execute spatial cross-validation\n",
        "spatial_cv = SpatialCrossValidator(n_splits=5)\n",
        "\n",
        "# Compare spatial CV and random CV\n",
        "results = spatial_cv.compare_with_random_cv(model, X_scaled, y, coords)\n",
        "\n",
        "# Analyze spatial autocorrelation\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Spatial Autocorrelation Analysis\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Calculate spatial distance matrix (simplified version for demonstration)\n",
        "print(\"Calculating spatial distances between samples...\")\n",
        "\n",
        "# Randomly select 100 samples to calculate (to avoid excessive computation)\n",
        "n_samples = min(100, len(coords))\n",
        "sample_idx = np.random.choice(len(coords), n_samples, replace=False)\n",
        "sample_coords = coords[sample_idx]\n",
        "\n",
        "# Calculate distance matrix\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "distances = squareform(pdist(sample_coords))\n",
        "\n",
        "# Analyze spatial autocorrelation\n",
        "print(f\"Calculated distance matrix for {n_samples} samples\")\n",
        "print(f\"Minimum distance: {distances[distances > 0].min():.4f}\")\n",
        "print(f\"Maximum distance: {distances.max():.4f}\")\n",
        "print(f\"Mean distance: {distances.mean():.4f}\")\n",
        "\n",
        "# Generate report\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Spatial Cross-Validation Report\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"\\nKey Findings:\")\n",
        "if results['random_mean_acc'] - results['spatial_mean_acc'] > 0.05:\n",
        "    print(\"⚠ Significant spatial autocorrelation detected:\")\n",
        "    print(f\"  Random CV accuracy is {results['random_mean_acc'] - results['spatial_mean_acc']:.4f} higher than spatial CV\")\n",
        "    print(\"  Recommendation: Report spatial CV results in the manuscript to avoid performance overestimation\")\n",
        "else:\n",
        "    print(\"✓ Spatial autocorrelation not significant:\")\n",
        "    print(f\"  Difference between random CV and spatial CV accuracy is only {results['random_mean_acc'] - results['spatial_mean_acc']:.4f}\")\n",
        "    print(\"  Model shows good spatial generalization capability\")\n",
        "\n",
        "print(f\"\\nManuscript Revision Suggestions:\")\n",
        "print(\"1. Add details of spatial cross-validation implementation in Methods section\")\n",
        "print(\"2. Report comparison results between spatial CV and random CV in Results section\")\n",
        "print(\"3. Analyze the impact of spatial autocorrelation on model performance in Discussion section\")\n",
        "\n",
        "# Save results\n",
        "import json\n",
        "import os\n",
        "os.makedirs('spatial_cv_results', exist_ok=True)\n",
        "\n",
        "with open('spatial_cv_results/spatial_cv_results.json', 'w') as f:\n",
        "    json.dump(results, f, indent=2)\n",
        "print(\"\\n✓ Spatial cross-validation results saved as: spatial_cv_results/spatial_cv_results.json\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Spatial Cross-Validation Completed!\")\n",
        "print(\"=\"*60)"
      ]
    }
  ]
}