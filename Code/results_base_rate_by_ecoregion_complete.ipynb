{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EuONoImcQf85"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_predict, StratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, cohen_kappa_score, precision_score, recall_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 读取数据\n",
        "df = pd.read_csv('/content/drive/MyDrive/merged_data_by_year_生态区级 (2).csv')\n",
        "\n",
        "# 检查数据\n",
        "print(\"数据形状:\", df.shape)\n",
        "print(\"列名:\", df.columns.tolist())\n",
        "print(\"\\n标签分布:\")\n",
        "print(df['b1'].value_counts())\n",
        "print(f\"PFCL比例: {df['b1'].mean():.4%}\")\n",
        "\n",
        "# 定义特征列和目标列\n",
        "exclude_cols = ['lat', 'lon', 'year', 'ID', 'b1']\n",
        "feature_cols = [col for col in df.columns if col not in exclude_cols]\n",
        "target_col = 'b1'\n",
        "\n",
        "print(f\"\\n特征数量: {len(feature_cols)}\")\n",
        "print(f\"目标变量: {target_col}\")\n",
        "\n",
        "# 获取所有生态区\n",
        "ecoregions = df['ID'].unique()\n",
        "print(f\"\\n生态区数量: {len(ecoregions)}\")\n",
        "print(f\"生态区: {ecoregions}\")\n",
        "\n",
        "# 初始化结果存储\n",
        "base_rate_results = []\n",
        "\n",
        "# 定义基础率范围 (0.5% 到 20%)\n",
        "base_rates_percent = np.concatenate([\n",
        "    [0.5, 1, 2, 3, 4, 5],\n",
        "    np.arange(6, 21, 1)\n",
        "])\n",
        "\n",
        "print(f\"\\n将测试的基础率范围: {base_rates_percent}%\")\n",
        "\n",
        "# 对每个生态区进行分析\n",
        "for ecoregion in tqdm(ecoregions, desc=\"处理生态区\"):\n",
        "    print(f\"\\n处理生态区: {ecoregion}\")\n",
        "\n",
        "    # 筛选当前生态区的数据\n",
        "    eco_data = df[df['ID'] == ecoregion].copy()\n",
        "\n",
        "    if len(eco_data) < 20:\n",
        "        print(f\"  生态区 {ecoregion} 数据不足 ({len(eco_data)} 行)，跳过\")\n",
        "        continue\n",
        "\n",
        "    X = eco_data[feature_cols]\n",
        "    y = eco_data[target_col]\n",
        "\n",
        "    # 检查类别平衡\n",
        "    class_counts = y.value_counts()\n",
        "    print(f\"  类别分布: 0={class_counts.get(0, 0)}, 1={class_counts.get(1, 0)}\")\n",
        "\n",
        "    if class_counts.get(1, 0) < 5:\n",
        "        print(f\"  PFCL样本过少，跳过\")\n",
        "        continue\n",
        "\n",
        "    # 使用分层交叉验证获得预测结果\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "    # 使用类别平衡的随机森林\n",
        "    clf = RandomForestClassifier(\n",
        "        n_estimators=100,\n",
        "        class_weight='balanced',\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    # 使用交叉验证获得预测\n",
        "    try:\n",
        "        y_pred = cross_val_predict(clf, X, y, cv=skf, method='predict')\n",
        "        y_pred_proba = cross_val_predict(clf, X, y, cv=skf, method='predict_proba')[:, 1]\n",
        "    except Exception as e:\n",
        "        print(f\"  交叉验证错误: {e}\")\n",
        "        continue\n",
        "\n",
        "    # 计算原始指标（1:1平衡采样）\n",
        "    cm_original = confusion_matrix(y, y_pred)\n",
        "    tn_original, fp_original, fn_original, tp_original = cm_original.ravel()\n",
        "\n",
        "    # 计算原始指标\n",
        "    oa_original = accuracy_score(y, y_pred)\n",
        "    f1_original = f1_score(y, y_pred)\n",
        "    kappa_original = cohen_kappa_score(y, y_pred)\n",
        "    pa_original = recall_score(y, y_pred)  # 生产者精度 = 召回率\n",
        "    ua_original = precision_score(y, y_pred)  # 用户精度 = 精确率\n",
        "\n",
        "    print(f\"  原始混淆矩阵: TN={tn_original}, FP={fp_original}, FN={fn_original}, TP={tp_original}\")\n",
        "    print(f\"  原始指标: OA={oa_original:.3f}, F1={f1_original:.3f}, Kappa={kappa_original:.3f}, PA={pa_original:.3f}, UA={ua_original:.3f}\")\n",
        "\n",
        "    # 进行基于基础率的敏感性分析\n",
        "    for base_rate_percent in base_rates_percent:\n",
        "        base_rate = base_rate_percent / 100  # 转换为小数\n",
        "\n",
        "        # 方法1：基于贝叶斯定理调整阈值（使用概率）\n",
        "        # 在平衡采样下，默认阈值是0.5\n",
        "        # 当先验概率改变时，最优阈值也改变\n",
        "        # 根据贝叶斯决策理论：新阈值 = base_rate * 成本比\n",
        "        # 这里假设成本比为1，所以新阈值 = base_rate\n",
        "\n",
        "        new_threshold = base_rate\n",
        "\n",
        "        # 应用新阈值\n",
        "        y_pred_adjusted = (y_pred_proba >= new_threshold).astype(int)\n",
        "\n",
        "        # 计算调整后的指标\n",
        "        cm_adjusted = confusion_matrix(y, y_pred_adjusted)\n",
        "        tn_adjusted, fp_adjusted, fn_adjusted, tp_adjusted = cm_adjusted.ravel()\n",
        "\n",
        "        # 计算调整后的指标\n",
        "        oa_adjusted = accuracy_score(y, y_pred_adjusted)\n",
        "        f1_adjusted = f1_score(y, y_pred_adjusted)\n",
        "        kappa_adjusted = cohen_kappa_score(y, y_pred_adjusted)\n",
        "        pa_adjusted = recall_score(y, y_pred_adjusted, zero_division=0)\n",
        "        ua_adjusted = precision_score(y, y_pred_adjusted, zero_division=0)\n",
        "\n",
        "        # 方法2：重加权混淆矩阵（作为验证）\n",
        "        # 原始训练是平衡的（各50%），但测试时基础率不同\n",
        "        # 调整因子：新分布 vs 旧分布\n",
        "        weight_non_pfcl = (1 - base_rate) / 0.5\n",
        "        weight_pfcl = base_rate / 0.5\n",
        "\n",
        "        # 调整原始混淆矩阵\n",
        "        tn_weighted = tn_original * weight_non_pfcl\n",
        "        fp_weighted = fp_original * weight_non_pfcl\n",
        "        fn_weighted = fn_original * weight_pfcl\n",
        "        tp_weighted = tp_original * weight_pfcl\n",
        "\n",
        "        # 从加权混淆矩阵计算指标\n",
        "        total_weighted = tn_weighted + fp_weighted + fn_weighted + tp_weighted\n",
        "\n",
        "        if total_weighted > 0:\n",
        "            oa_weighted = (tn_weighted + tp_weighted) / total_weighted\n",
        "        else:\n",
        "            oa_weighted = 0\n",
        "\n",
        "        if tp_weighted + fn_weighted > 0:\n",
        "            pa_weighted = tp_weighted / (tp_weighted + fn_weighted)\n",
        "        else:\n",
        "            pa_weighted = 0\n",
        "\n",
        "        if tp_weighted + fp_weighted > 0:\n",
        "            ua_weighted = tp_weighted / (tp_weighted + fp_weighted)\n",
        "        else:\n",
        "            ua_weighted = 0\n",
        "\n",
        "        if pa_weighted + ua_weighted > 0:\n",
        "            f1_weighted = 2 * (pa_weighted * ua_weighted) / (pa_weighted + ua_weighted)\n",
        "        else:\n",
        "            f1_weighted = 0\n",
        "\n",
        "        # 计算加权Kappa\n",
        "        # Po = OA_weighted\n",
        "        # Pe = (预测为正的概率 * 实际为正的概率 + 预测为负的概率 * 实际为负的概率)\n",
        "        pred_pos_rate_weighted = (tp_weighted + fp_weighted) / total_weighted if total_weighted > 0 else 0\n",
        "        actual_pos_rate_weighted = (tp_weighted + fn_weighted) / total_weighted if total_weighted > 0 else 0\n",
        "        pred_neg_rate_weighted = (tn_weighted + fn_weighted) / total_weighted if total_weighted > 0 else 0\n",
        "        actual_neg_rate_weighted = (tn_weighted + fp_weighted) / total_weighted if total_weighted > 0 else 0\n",
        "\n",
        "        pe_weighted = pred_pos_rate_weighted * actual_pos_rate_weighted + pred_neg_rate_weighted * actual_neg_rate_weighted\n",
        "\n",
        "        if 1 - pe_weighted > 0:\n",
        "            kappa_weighted = (oa_weighted - pe_weighted) / (1 - pe_weighted)\n",
        "        else:\n",
        "            kappa_weighted = 0\n",
        "\n",
        "        # 存储结果 - 使用阈值调整方法的结果\n",
        "        base_rate_results.append({\n",
        "            'ecoregion': ecoregion,\n",
        "            'pfcl_base_rate_percent': base_rate_percent,\n",
        "\n",
        "            # 原始指标（1:1平衡采样）\n",
        "            'OA_original': oa_original,\n",
        "            'F1_original': f1_original,\n",
        "            'Kappa_original': kappa_original,\n",
        "            'PA_original': pa_original,\n",
        "            'UA_original': ua_original,\n",
        "\n",
        "            # 调整后的指标（使用阈值调整）\n",
        "            'OA_adj': oa_adjusted,\n",
        "            'F1_adj': f1_adjusted,\n",
        "            'Kappa_adj': kappa_adjusted,\n",
        "            'PA_adj': pa_adjusted,\n",
        "            'UA_adj': ua_adjusted,\n",
        "\n",
        "            # 加权混淆矩阵方法的结果（作为参考）\n",
        "            'OA_weighted': oa_weighted,\n",
        "            'F1_weighted': f1_weighted,\n",
        "            'Kappa_weighted': kappa_weighted,\n",
        "            'PA_weighted': pa_weighted,\n",
        "            'UA_weighted': ua_weighted,\n",
        "\n",
        "            # 其他信息\n",
        "            'samples': len(eco_data),\n",
        "            'pfcl_count': class_counts.get(1, 0),\n",
        "            'new_threshold': new_threshold,\n",
        "\n",
        "            # 原始混淆矩阵\n",
        "            'tn_original': tn_original,\n",
        "            'fp_original': fp_original,\n",
        "            'fn_original': fn_original,\n",
        "            'tp_original': tp_original,\n",
        "\n",
        "            # 调整后混淆矩阵\n",
        "            'tn_adjusted': tn_adjusted,\n",
        "            'fp_adjusted': fp_adjusted,\n",
        "            'fn_adjusted': fn_adjusted,\n",
        "            'tp_adjusted': tp_adjusted\n",
        "        })\n",
        "\n",
        "# 转换为DataFrame\n",
        "results_df = pd.DataFrame(base_rate_results)\n",
        "\n",
        "# 保存结果到CSV\n",
        "output_path = '/content/drive/MyDrive/results_base_rate_by_ecoregion_complete.csv'\n",
        "results_df.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"\\n结果已保存到: {output_path}\")\n",
        "print(f\"结果形状: {results_df.shape}\")\n",
        "print(\"\\n结果预览:\")\n",
        "print(results_df.head(10))\n",
        "\n",
        "# 验证：对于基础率=50%，调整后的指标应接近原始指标（因为训练就是50:50平衡的）\n",
        "print(\"\\n验证: 基础率=50%时的对比\")\n",
        "for ecoregion in results_df['ecoregion'].unique()[:3]:\n",
        "    subset = results_df[(results_df['ecoregion'] == ecoregion) &\n",
        "                        (results_df['pfcl_base_rate_percent'] == 50)]\n",
        "    if len(subset) > 0:\n",
        "        row = subset.iloc[0]\n",
        "        print(f\"\\n生态区 {ecoregion}:\")\n",
        "        print(f\"  OA: 原始={row['OA_original']:.3f}, 调整={row['OA_adj']:.3f}, 差异={abs(row['OA_original']-row['OA_adj']):.4f}\")\n",
        "        print(f\"  PA: 原始={row['PA_original']:.3f}, 调整={row['PA_adj']:.3f}, 差异={abs(row['PA_original']-row['PA_adj']):.4f}\")\n",
        "        print(f\"  UA: 原始={row['UA_original']:.3f}, 调整={row['UA_adj']:.3f}, 差异={abs(row['UA_original']-row['UA_adj']):.4f}\")\n",
        "\n",
        "# 创建可视化\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
        "\n",
        "# 1. PA随基础率变化\n",
        "for ecoregion in results_df['ecoregion'].unique()[:5]:\n",
        "    eco_data = results_df[results_df['ecoregion'] == ecoregion]\n",
        "    axes[0, 0].plot(eco_data['pfcl_base_rate_percent'], eco_data['PA_adj'],\n",
        "                    label=ecoregion, marker='o', markersize=3)\n",
        "axes[0, 0].set_xlabel('PFCL Base Rate (%)')\n",
        "axes[0, 0].set_ylabel('Adjusted Producer Accuracy (PA)')\n",
        "axes[0, 0].set_title('PA vs PFCL Base Rate')\n",
        "axes[0, 0].legend(fontsize=8)\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# 2. UA随基础率变化\n",
        "for ecoregion in results_df['ecoregion'].unique()[:5]:\n",
        "    eco_data = results_df[results_df['ecoregion'] == ecoregion]\n",
        "    axes[0, 1].plot(eco_data['pfcl_base_rate_percent'], eco_data['UA_adj'],\n",
        "                    label=ecoregion, marker='s', markersize=3)\n",
        "axes[0, 1].set_xlabel('PFCL Base Rate (%)')\n",
        "axes[0, 1].set_ylabel('Adjusted User Accuracy (UA)')\n",
        "axes[0, 1].set_title('UA vs PFCL Base Rate')\n",
        "axes[0, 1].legend(fontsize=8)\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# 3. F1随基础率变化\n",
        "for ecoregion in results_df['ecoregion'].unique()[:5]:\n",
        "    eco_data = results_df[results_df['ecoregion'] == ecoregion]\n",
        "    axes[0, 2].plot(eco_data['pfcl_base_rate_percent'], eco_data['F1_adj'],\n",
        "                    label=ecoregion, marker='^', markersize=3)\n",
        "axes[0, 2].set_xlabel('PFCL Base Rate (%)')\n",
        "axes[0, 2].set_ylabel('Adjusted F1 Score')\n",
        "axes[0, 2].set_title('F1 vs PFCL Base Rate')\n",
        "axes[0, 2].legend(fontsize=8)\n",
        "axes[0, 2].grid(True, alpha=0.3)\n",
        "\n",
        "# 4. OA随基础率变化\n",
        "for ecoregion in results_df['ecoregion'].unique()[:5]:\n",
        "    eco_data = results_df[results_df['ecoregion'] == ecoregion]\n",
        "    axes[1, 0].plot(eco_data['pfcl_base_rate_percent'], eco_data['OA_adj'],\n",
        "                    label=ecoregion, marker='d', markersize=3)\n",
        "axes[1, 0].set_xlabel('PFCL Base Rate (%)')\n",
        "axes[1, 0].set_ylabel('Adjusted Overall Accuracy (OA)')\n",
        "axes[1, 0].set_title('OA vs PFCL Base Rate')\n",
        "axes[1, 0].legend(fontsize=8)\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# 5. Kappa随基础率变化\n",
        "for ecoregion in results_df['ecoregion'].unique()[:5]:\n",
        "    eco_data = results_df[results_df['ecoregion'] == ecoregion]\n",
        "    axes[1, 1].plot(eco_data['pfcl_base_rate_percent'], eco_data['Kappa_adj'],\n",
        "                    label=ecoregion, marker='v', markersize=3)\n",
        "axes[1, 1].set_xlabel('PFCL Base Rate (%)')\n",
        "axes[1, 1].set_ylabel('Adjusted Kappa Coefficient')\n",
        "axes[1, 1].set_title('Kappa vs PFCL Base Rate')\n",
        "axes[1, 1].legend(fontsize=8)\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# 6. 阈值随基础率变化\n",
        "for ecoregion in results_df['ecoregion'].unique()[:5]:\n",
        "    eco_data = results_df[results_df['ecoregion'] == ecoregion]\n",
        "    axes[1, 2].plot(eco_data['pfcl_base_rate_percent'], eco_data['new_threshold'],\n",
        "                    label=ecoregion, marker='*', markersize=3)\n",
        "axes[1, 2].set_xlabel('PFCL Base Rate (%)')\n",
        "axes[1, 2].set_ylabel('Adjusted Threshold')\n",
        "axes[1, 2].set_title('Decision Threshold vs PFCL Base Rate')\n",
        "axes[1, 2].legend(fontsize=8)\n",
        "axes[1, 2].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('/content/drive/MyDrive/base_rate_sensitivity_complete_analysis.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# 生成汇总统计表\n",
        "print(\"\\n汇总统计 - 不同基础率下的平均表现:\")\n",
        "summary_stats = results_df.groupby('pfcl_base_rate_percent').agg({\n",
        "    'OA_adj': 'mean',\n",
        "    'F1_adj': 'mean',\n",
        "    'Kappa_adj': 'mean',\n",
        "    'PA_adj': 'mean',\n",
        "    'UA_adj': 'mean'\n",
        "}).round(3)\n",
        "\n",
        "print(summary_stats)\n",
        "\n",
        "# 计算乐观偏差（在典型基础率下，如1%）\n",
        "ref_rate = 1.0\n",
        "optimism_bias = []\n",
        "\n",
        "for ecoregion in results_df['ecoregion'].unique():\n",
        "    eco_data = results_df[results_df['ecoregion'] == ecoregion]\n",
        "\n",
        "    # 原始指标（50%基础率）\n",
        "    orig_row = eco_data[eco_data['pfcl_base_rate_percent'] == 50].iloc[0] if 50 in eco_data['pfcl_base_rate_percent'].values else None\n",
        "\n",
        "    # 调整后指标（参考基础率，如1%）\n",
        "    adj_row = eco_data[eco_data['pfcl_base_rate_percent'] == ref_rate].iloc[0] if ref_rate in eco_data['pfcl_base_rate_percent'].values else None\n",
        "\n",
        "    if orig_row is not None and adj_row is not None:\n",
        "        optimism_bias.append({\n",
        "            'ecoregion': ecoregion,\n",
        "            'OA_bias': orig_row['OA_original'] - adj_row['OA_adj'],\n",
        "            'F1_bias': orig_row['F1_original'] - adj_row['F1_adj'],\n",
        "            'Kappa_bias': orig_row['Kappa_original'] - adj_row['Kappa_adj'],\n",
        "            'PA_bias': orig_row['PA_original'] - adj_row['PA_adj'],\n",
        "            'UA_bias': orig_row['UA_original'] - adj_row['UA_adj'],\n",
        "            'OA_relative_bias%': (orig_row['OA_original'] - adj_row['OA_adj']) / orig_row['OA_original'] * 100 if orig_row['OA_original'] > 0 else 0,\n",
        "            'UA_relative_bias%': (orig_row['UA_original'] - adj_row['UA_adj']) / orig_row['UA_original'] * 100 if orig_row['UA_original'] > 0 else 0\n",
        "        })\n",
        "\n",
        "if optimism_bias:\n",
        "    bias_df = pd.DataFrame(optimism_bias)\n",
        "    print(f\"\\n乐观偏差分析 (基于{ref_rate}%基础率):\")\n",
        "    print(bias_df.round(3))\n",
        "\n",
        "    # 保存乐观偏差结果\n",
        "    bias_df.to_csv('/content/drive/MyDrive/optimism_bias_analysis_complete.csv', index=False)\n",
        "\n",
        "    # 计算平均乐观偏差\n",
        "    print(f\"\\n平均乐观偏差 (基于{ref_rate}%基础率):\")\n",
        "    avg_bias = bias_df[['OA_bias', 'F1_bias', 'Kappa_bias', 'PA_bias', 'UA_bias']].mean()\n",
        "    print(avg_bias.round(3))\n",
        "\n",
        "print(\"\\n分析完成!\")"
      ]
    }
  ]
}