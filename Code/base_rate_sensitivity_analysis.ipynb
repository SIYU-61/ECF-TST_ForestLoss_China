{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EuONoImcQf85"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_predict, StratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, cohen_kappa_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 读取数据\n",
        "df = pd.read_csv('/content/drive/MyDrive/merged_data_by_year_生态区级 (2).csv')\n",
        "\n",
        "# 检查数据\n",
        "print(\"数据形状:\", df.shape)\n",
        "print(\"列名:\", df.columns.tolist())\n",
        "print(\"\\n标签分布:\")\n",
        "print(df['b1'].value_counts())\n",
        "print(f\"PFCL比例: {df['b1'].mean():.4%}\")\n",
        "\n",
        "# 定义特征列和目标列\n",
        "# 排除非特征列：lat, lon, year, ID, b1（目标）\n",
        "exclude_cols = ['lat', 'lon', 'year', 'ID', 'b1']\n",
        "feature_cols = [col for col in df.columns if col not in exclude_cols]\n",
        "target_col = 'b1'\n",
        "\n",
        "print(f\"\\n特征数量: {len(feature_cols)}\")\n",
        "print(f\"目标变量: {target_col}\")\n",
        "\n",
        "# 获取所有生态区\n",
        "ecoregions = df['ID'].unique()\n",
        "print(f\"\\n生态区数量: {len(ecoregions)}\")\n",
        "print(f\"生态区: {ecoregions}\")\n",
        "\n",
        "# 初始化结果存储\n",
        "base_rate_results = []\n",
        "\n",
        "# 定义基础率范围 (0.5% 到 20%)\n",
        "base_rates_percent = np.concatenate([\n",
        "    [0.5, 1, 2, 3, 4, 5],\n",
        "    np.arange(6, 21, 1)\n",
        "])\n",
        "\n",
        "print(f\"\\n将测试的基础率范围: {base_rates_percent}%\")\n",
        "\n",
        "# 对每个生态区进行分析\n",
        "for ecoregion in tqdm(ecoregions, desc=\"处理生态区\"):\n",
        "    print(f\"\\n处理生态区: {ecoregion}\")\n",
        "\n",
        "    # 筛选当前生态区的数据\n",
        "    eco_data = df[df['ID'] == ecoregion].copy()\n",
        "\n",
        "    if len(eco_data) < 20:\n",
        "        print(f\"  生态区 {ecoregion} 数据不足 ({len(eco_data)} 行)，跳过\")\n",
        "        continue\n",
        "\n",
        "    X = eco_data[feature_cols]\n",
        "    y = eco_data[target_col]\n",
        "\n",
        "    # 检查类别平衡\n",
        "    class_counts = y.value_counts()\n",
        "    print(f\"  类别分布: 0={class_counts.get(0, 0)}, 1={class_counts.get(1, 0)}\")\n",
        "\n",
        "    if class_counts.get(1, 0) < 5:\n",
        "        print(f\"  PFCL样本过少，跳过\")\n",
        "        continue\n",
        "\n",
        "    # 使用分层交叉验证获得预测结果\n",
        "    # 使用1:1类别平衡采样（通过分层交叉验证和平衡的随机森林）\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "    # 使用类别平衡的随机森林\n",
        "    clf = RandomForestClassifier(\n",
        "        n_estimators=100,\n",
        "        class_weight='balanced',  # 平衡类别权重\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    # 使用交叉验证获得预测\n",
        "    try:\n",
        "        y_pred = cross_val_predict(clf, X, y, cv=skf, method='predict')\n",
        "        y_pred_proba = cross_val_predict(clf, X, y, cv=skf, method='predict_proba')[:, 1]\n",
        "    except Exception as e:\n",
        "        print(f\"  交叉验证错误: {e}\")\n",
        "        continue\n",
        "\n",
        "    # 计算基础指标\n",
        "    cm = confusion_matrix(y, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "    # 计算常规指标\n",
        "    oa = accuracy_score(y, y_pred)\n",
        "    f1 = f1_score(y, y_pred)\n",
        "    kappa = cohen_kappa_score(y, y_pred)\n",
        "\n",
        "    # 计算PA和UA（生产者精度和用户精度）\n",
        "    if tp + fn > 0:\n",
        "        pa = tp / (tp + fn)  # 生产者精度（召回率）\n",
        "    else:\n",
        "        pa = 0\n",
        "\n",
        "    if tp + fp > 0:\n",
        "        ua = tp / (tp + fp)  # 用户精度（精确率）\n",
        "    else:\n",
        "        ua = 0\n",
        "\n",
        "    print(f\"  混淆矩阵: TN={tn}, FP={fp}, FN={fn}, TP={tp}\")\n",
        "    print(f\"  OA={oa:.3f}, F1={f1:.3f}, Kappa={kappa:.3f}\")\n",
        "    print(f\"  PA={pa:.3f}, UA={ua:.3f}\")\n",
        "\n",
        "    # 进行基于基础率的敏感性分析\n",
        "    for base_rate_percent in base_rates_percent:\n",
        "        base_rate = base_rate_percent / 100  # 转换为小数\n",
        "\n",
        "        # 调整混淆矩阵以反映新的基础率\n",
        "        # 假设原始训练数据是1:1平衡的（先验概率各为0.5）\n",
        "        # 我们需要根据实际基础率重新加权混淆矩阵\n",
        "\n",
        "        # 实际中，非PFCL和PFCL的比例为 (1-base_rate):base_rate\n",
        "        # 但在平衡采样中，我们假设每个类别的先验概率为0.5\n",
        "\n",
        "        # 计算调整因子\n",
        "        # 对于非PFCL行：乘以 (1-base_rate)/0.5\n",
        "        # 对于PFCL行：乘以 base_rate/0.5\n",
        "        weight_non_pfcl = (1 - base_rate) / 0.5\n",
        "        weight_pfcl = base_rate / 0.5\n",
        "\n",
        "        # 调整混淆矩阵\n",
        "        adjusted_cm = np.array([\n",
        "            [tn * weight_non_pfcl, fp * weight_non_pfcl],\n",
        "            [fn * weight_pfcl, tp * weight_pfcl]\n",
        "        ])\n",
        "\n",
        "        # 计算调整后的PA和UA\n",
        "        adjusted_tp = adjusted_cm[1, 1]\n",
        "        adjusted_fn = adjusted_cm[1, 0]\n",
        "        adjusted_fp = adjusted_cm[0, 1]\n",
        "\n",
        "        if adjusted_tp + adjusted_fn > 0:\n",
        "            pa_adj = adjusted_tp / (adjusted_tp + adjusted_fn)\n",
        "        else:\n",
        "            pa_adj = 0\n",
        "\n",
        "        if adjusted_tp + adjusted_fp > 0:\n",
        "            ua_adj = adjusted_tp / (adjusted_tp + adjusted_fp)\n",
        "        else:\n",
        "            ua_adj = 0\n",
        "\n",
        "        # 存储结果\n",
        "        base_rate_results.append({\n",
        "            'ecoregion': ecoregion,\n",
        "            'pfcl_base_rate_percent': base_rate_percent,\n",
        "            'PA_adj': pa_adj,\n",
        "            'UA_adj': ua_adj,\n",
        "            'OA': oa,\n",
        "            'F1': f1,\n",
        "            'Kappa': kappa,\n",
        "            'PA_original': pa,\n",
        "            'UA_original': ua\n",
        "        })\n",
        "\n",
        "# 转换为DataFrame\n",
        "results_df = pd.DataFrame(base_rate_results)\n",
        "\n",
        "# 保存结果到CSV\n",
        "output_path = '/content/drive/MyDrive/results_base_rate_by_ecoregion.csv'\n",
        "results_df.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"\\n结果已保存到: {output_path}\")\n",
        "print(f\"结果形状: {results_df.shape}\")\n",
        "print(\"\\n结果预览:\")\n",
        "print(results_df.head(10))\n",
        "\n",
        "# 创建可视化\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# 绘制PA随基础率变化\n",
        "for ecoregion in results_df['ecoregion'].unique()[:5]:  # 只显示前5个生态区\n",
        "    eco_data = results_df[results_df['ecoregion'] == ecoregion]\n",
        "    axes[0].plot(eco_data['pfcl_base_rate_percent'], eco_data['PA_adj'],\n",
        "                label=ecoregion, marker='o', markersize=4)\n",
        "\n",
        "axes[0].set_xlabel('PFCL Base Rate (%)')\n",
        "axes[0].set_ylabel('Adjusted Producer Accuracy (PA)')\n",
        "axes[0].set_title('PA vs PFCL Base Rate by Ecoregion')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# 绘制UA随基础率变化\n",
        "for ecoregion in results_df['ecoregion'].unique()[:5]:\n",
        "    eco_data = results_df[results_df['ecoregion'] == ecoregion]\n",
        "    axes[1].plot(eco_data['pfcl_base_rate_percent'], eco_data['UA_adj'],\n",
        "                label=ecoregion, marker='s', markersize=4)\n",
        "\n",
        "axes[1].set_xlabel('PFCL Base Rate (%)')\n",
        "axes[1].set_ylabel('Adjusted User Accuracy (UA)')\n",
        "axes[1].set_title('UA vs PFCL Base Rate by Ecoregion')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('/content/drive/MyDrive/base_rate_sensitivity_analysis.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# 生成汇总统计表\n",
        "summary_stats = results_df.groupby('ecoregion').agg({\n",
        "    'PA_adj': ['min', 'max', 'mean'],\n",
        "    'UA_adj': ['min', 'max', 'mean'],\n",
        "    'OA': 'first',\n",
        "    'F1': 'first',\n",
        "    'Kappa': 'first'\n",
        "}).round(3)\n",
        "\n",
        "print(\"\\n汇总统计:\")\n",
        "print(summary_stats)\n",
        "\n",
        "# 计算不同基础率下的平均表现\n",
        "base_rate_summary = results_df.groupby('pfcl_base_rate_percent').agg({\n",
        "    'PA_adj': 'mean',\n",
        "    'UA_adj': 'mean'\n",
        "}).round(3)\n",
        "\n",
        "print(\"\\n不同基础率下的平均表现:\")\n",
        "print(base_rate_summary)\n",
        "\n",
        "# 计算乐观偏差（1:1平衡采样与基础率调整后的差异）\n",
        "# 使用基础率=1%作为参考\n",
        "ref_rate = 1.0\n",
        "ref_results = results_df[results_df['pfcl_base_rate_percent'] == ref_rate]\n",
        "\n",
        "if len(ref_results) > 0:\n",
        "    optimism_bias = []\n",
        "    for _, row in ref_results.iterrows():\n",
        "        bias_pa = row['PA_original'] - row['PA_adj']\n",
        "        bias_ua = row['UA_original'] - row['UA_adj']\n",
        "        optimism_bias.append({\n",
        "            'ecoregion': row['ecoregion'],\n",
        "            'PA_bias': bias_pa,\n",
        "            'UA_bias': bias_ua,\n",
        "            'relative_PA_bias': bias_pa / row['PA_original'] if row['PA_original'] > 0 else 0,\n",
        "            'relative_UA_bias': bias_ua / row['UA_original'] if row['UA_original'] > 0 else 0\n",
        "        })\n",
        "\n",
        "    bias_df = pd.DataFrame(optimism_bias)\n",
        "    print(\"\\n乐观偏差分析 (基于1%基础率):\")\n",
        "    print(bias_df.round(3))\n",
        "\n",
        "    # 保存乐观偏差结果\n",
        "    bias_df.to_csv('/content/drive/MyDrive/optimism_bias_analysis.csv', index=False)\n",
        "\n",
        "print(\"\\n分析完成!\")"
      ]
    }
  ]
}