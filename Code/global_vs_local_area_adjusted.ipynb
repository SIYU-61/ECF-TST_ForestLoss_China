{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EuONoImcQf85"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, confusion_matrix, cohen_kappa_score\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "import os\n",
        "import time\n",
        "import joblib\n",
        "import pickle\n",
        "import random\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(f\"{'='*80}\")\n",
        "print(\"全局模型 vs 分区模型性能比较（包含面积调整）\")\n",
        "print(f\"{'='*80}\")\n",
        "\n",
        "# 设置随机种子保证可重复性\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "# 1. 加载数据\n",
        "print(\"\\n1. 加载数据...\")\n",
        "df = pd.read_csv('/content/drive/MyDrive/merged_data_by_year_生态区级 (2).csv')\n",
        "df = df.dropna(subset=['ID'])\n",
        "df['ID'] = df['ID'].astype(str).str.strip()\n",
        "\n",
        "exclude_cols = ['lat', 'lon', 'year', 'ID', 'b1']\n",
        "feature_cols = [col for col in df.columns if col not in exclude_cols]\n",
        "target_col = 'b1'\n",
        "\n",
        "# 计算全国的PFCL基础率（面积调整的基准）\n",
        "national_base_rate = df['b1'].mean()\n",
        "print(f\"  全国PFCL基础率: {national_base_rate:.4%}\")\n",
        "\n",
        "print(f\"  总数据量: {len(df)} 行\")\n",
        "print(f\"  特征数量: {len(feature_cols)}\")\n",
        "print(f\"  生态区数量: {df['ID'].nunique()}\")\n",
        "\n",
        "# 2. 为每个生态区划分训练集和测试集\n",
        "print(f\"\\n2. 为每个生态区划分训练集(80%)和测试集(20%)...\")\n",
        "\n",
        "# 存储划分结果和本地模型\n",
        "ecoregion_data = {}\n",
        "global_train_samples = []\n",
        "\n",
        "# 计算每个生态区的基础率（用于面积调整）\n",
        "ecoregion_base_rates = {}\n",
        "\n",
        "# 遍历每个生态区\n",
        "for ecoregion_id in df['ID'].unique():\n",
        "    eco_data = df[df['ID'] == ecoregion_id].copy()\n",
        "\n",
        "    # 计算生态区基础率\n",
        "    ecoregion_base_rate = eco_data['b1'].mean()\n",
        "    ecoregion_base_rates[ecoregion_id] = ecoregion_base_rate\n",
        "\n",
        "    if len(eco_data) < 10:  # 如果样本太少，跳过\n",
        "        print(f\"  警告: 生态区 {ecoregion_id} 样本数太少 ({len(eco_data)}), 跳过\")\n",
        "        continue\n",
        "\n",
        "    # 划分训练集和测试集\n",
        "    X = eco_data[feature_cols].values\n",
        "    y = eco_data[target_col].values\n",
        "\n",
        "    # 使用分层抽样，确保正负样本比例\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    # 存储划分结果\n",
        "    ecoregion_data[ecoregion_id] = {\n",
        "        'X_train': X_train,\n",
        "        'y_train': y_train,\n",
        "        'X_test': X_test,\n",
        "        'y_test': y_test,\n",
        "        'n_total': len(eco_data),\n",
        "        'positive_ratio': y.mean(),\n",
        "        'base_rate': ecoregion_base_rate,  # 生态区基础率\n",
        "        'local_model': None,\n",
        "        'local_model_trained': False\n",
        "    }\n",
        "\n",
        "    # 收集全局训练样本\n",
        "    for i in range(len(X_train)):\n",
        "        global_train_samples.append({\n",
        "            'features': X_train[i],\n",
        "            'label': y_train[i],\n",
        "            'ecoregion': ecoregion_id\n",
        "        })\n",
        "\n",
        "print(f\"\\n  全局训练样本总数: {len(global_train_samples)}\")\n",
        "print(f\"  有效生态区数量: {len(ecoregion_data)}\")\n",
        "\n",
        "# 3. 从全局训练样本中随机抽取50%\n",
        "print(f\"\\n3. 从全局训练样本中随机抽取50%用于训练全局模型...\")\n",
        "sample_size = int(len(global_train_samples) * 0.1)\n",
        "sampled_indices = random.sample(range(len(global_train_samples)), sample_size)\n",
        "\n",
        "# 构建全局训练集\n",
        "X_global_train = np.array([global_train_samples[i]['features'] for i in sampled_indices])\n",
        "y_global_train = np.array([global_train_samples[i]['label'] for i in sampled_indices])\n",
        "\n",
        "print(f\"  抽取的训练样本数: {len(X_global_train)}\")\n",
        "print(f\"  正样本比例: {y_global_train.mean():.2%}\")\n",
        "\n",
        "# 4. 训练全局模型\n",
        "print(f\"\\n4. 训练全局模型...\")\n",
        "rf_params = {\n",
        "    'n_estimators': 100,\n",
        "    'max_depth': 15,\n",
        "    'min_samples_split': 20,\n",
        "    'min_samples_leaf': 10,\n",
        "    'max_features': 'sqrt',\n",
        "    'class_weight': 'balanced',\n",
        "    'random_state': 42,\n",
        "    'n_jobs': -1,\n",
        "    'verbose': 0\n",
        "}\n",
        "\n",
        "start_time = time.time()\n",
        "global_model = RandomForestClassifier(**rf_params)\n",
        "global_model.fit(X_global_train, y_global_train)\n",
        "global_training_time = time.time() - start_time\n",
        "\n",
        "print(f\"  全局模型训练完成! 耗时: {global_training_time:.1f} 秒\")\n",
        "\n",
        "# 5. 训练每个生态区的本地模型\n",
        "print(f\"\\n5. 训练每个生态区的本地模型...\")\n",
        "local_models = {}\n",
        "local_training_times = []\n",
        "\n",
        "for ecoregion_id, data in ecoregion_data.items():\n",
        "    X_train = data['X_train']\n",
        "    y_train = data['y_train']\n",
        "\n",
        "    if len(X_train) < 20:\n",
        "        print(f\"  警告: 生态区 {ecoregion_id} 训练样本太少 ({len(X_train)}), 跳过本地模型训练\")\n",
        "        continue\n",
        "\n",
        "    print(f\"  训练生态区 {ecoregion_id} 的本地模型 ({len(X_train)} 个训练样本)...\")\n",
        "\n",
        "    start_time = time.time()\n",
        "    local_model = RandomForestClassifier(**rf_params)\n",
        "    local_model.fit(X_train, y_train)\n",
        "    training_time = time.time() - start_time\n",
        "    local_training_times.append(training_time)\n",
        "\n",
        "    local_models[ecoregion_id] = local_model\n",
        "    ecoregion_data[ecoregion_id]['local_model'] = local_model\n",
        "    ecoregion_data[ecoregion_id]['local_model_trained'] = True\n",
        "\n",
        "print(f\"\\n  本地模型训练完成!\")\n",
        "print(f\"  共训练了 {len(local_models)} 个本地模型\")\n",
        "\n",
        "# 定义面积调整函数\n",
        "def calculate_area_adjusted_metrics(y_true, y_pred_proba, base_rate, original_threshold=0.5):\n",
        "    \"\"\"\n",
        "    计算面积调整后的指标\n",
        "\n",
        "    参数:\n",
        "    y_true: 真实标签\n",
        "    y_pred_proba: 预测概率（正类的概率）\n",
        "    base_rate: 实际基础率（PFCL在景观中的比例）\n",
        "    original_threshold: 原始分类阈值（默认0.5，对应1:1平衡采样）\n",
        "\n",
        "    返回:\n",
        "    调整后的各项指标\n",
        "    \"\"\"\n",
        "    # 根据基础率调整阈值\n",
        "    # 贝叶斯调整：新阈值 = base_rate / (base_rate + (1-base_rate) * (1/原始阈值 - 1))\n",
        "    adjusted_threshold = base_rate / (base_rate + (1-base_rate) * (1/original_threshold - 1))\n",
        "\n",
        "    # 使用调整后的阈值进行分类\n",
        "    y_pred_adjusted = (y_pred_proba >= adjusted_threshold).astype(int)\n",
        "\n",
        "    # 计算混淆矩阵\n",
        "    cm = confusion_matrix(y_true, y_pred_adjusted)\n",
        "    if cm.shape == (2, 2):\n",
        "        tn, fp, fn, tp = cm.ravel()\n",
        "    else:\n",
        "        # 如果只有一个类别\n",
        "        if len(np.unique(y_pred_adjusted)) == 1:\n",
        "            if y_pred_adjusted[0] == 0:\n",
        "                tn, fp, fn, tp = len(y_true), 0, 0, 0\n",
        "            else:\n",
        "                tn, fp, fn, tp = 0, 0, 0, len(y_true)\n",
        "        else:\n",
        "            # 这种情况不应该发生，但以防万一\n",
        "            return {k: np.nan for k in ['OA', 'F1', 'Kappa', 'PA', 'UA']}\n",
        "\n",
        "    # 计算调整后的指标\n",
        "    total = tn + fp + fn + tp\n",
        "\n",
        "    if total > 0:\n",
        "        oa_adj = (tn + tp) / total\n",
        "    else:\n",
        "        oa_adj = 0\n",
        "\n",
        "    if tp + fn > 0:\n",
        "        pa_adj = tp / (tp + fn)  # 生产者精度\n",
        "    else:\n",
        "        pa_adj = 0\n",
        "\n",
        "    if tp + fp > 0:\n",
        "        ua_adj = tp / (tp + fp)  # 用户精度\n",
        "    else:\n",
        "        ua_adj = 0\n",
        "\n",
        "    if pa_adj + ua_adj > 0:\n",
        "        f1_adj = 2 * (pa_adj * ua_adj) / (pa_adj + ua_adj)\n",
        "    else:\n",
        "        f1_adj = 0\n",
        "\n",
        "    # 计算Kappa\n",
        "    # 期望一致率 Pe\n",
        "    p_observed = oa_adj\n",
        "    p_expected = ((tn + fp) * (tn + fn) + (fn + tp) * (fp + tp)) / (total * total) if total > 0 else 0\n",
        "\n",
        "    if 1 - p_expected > 0:\n",
        "        kappa_adj = (p_observed - p_expected) / (1 - p_expected)\n",
        "    else:\n",
        "        kappa_adj = 0\n",
        "\n",
        "    return {\n",
        "        'OA_adj': oa_adj,\n",
        "        'F1_adj': f1_adj,\n",
        "        'Kappa_adj': kappa_adj,\n",
        "        'PA_adj': pa_adj,\n",
        "        'UA_adj': ua_adj,\n",
        "        'adjusted_threshold': adjusted_threshold,\n",
        "        'tn': tn,\n",
        "        'fp': fp,\n",
        "        'fn': fn,\n",
        "        'tp': tp\n",
        "    }\n",
        "\n",
        "# 6. 在每个生态区的测试集上评估全局模型和本地模型（包含面积调整）\n",
        "print(f\"\\n6. 在每个生态区的测试集上评估模型性能（包含面积调整）...\")\n",
        "\n",
        "results = []\n",
        "national_test_data = []  # 收集全国测试数据，用于计算全国指标\n",
        "\n",
        "for ecoregion_id, data in ecoregion_data.items():\n",
        "    X_test = data['X_test']\n",
        "    y_test = data['y_test']\n",
        "\n",
        "    if len(X_test) == 0:\n",
        "        continue\n",
        "\n",
        "    # 收集全国测试数据\n",
        "    for i in range(len(X_test)):\n",
        "        national_test_data.append({\n",
        "            'features': X_test[i],\n",
        "            'label': y_test[i],\n",
        "            'ecoregion': ecoregion_id\n",
        "        })\n",
        "\n",
        "    # 获取生态区基础率（用于面积调整）\n",
        "    eco_base_rate = data['base_rate']\n",
        "\n",
        "    # 使用全局模型预测\n",
        "    y_pred_global = global_model.predict(X_test)\n",
        "    y_pred_proba_global = global_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # 计算全局模型原始指标（1:1平衡采样下的指标）\n",
        "    oa_global = accuracy_score(y_test, y_pred_global)\n",
        "    f1_global = f1_score(y_test, y_pred_global, zero_division=0)\n",
        "    pa_global = recall_score(y_test, y_pred_global, zero_division=0)\n",
        "    ua_global = precision_score(y_test, y_pred_global, zero_division=0)\n",
        "    kappa_global = cohen_kappa_score(y_test, y_pred_global)\n",
        "\n",
        "    # 计算全局模型面积调整后的指标（使用生态区基础率）\n",
        "    global_adj_metrics = calculate_area_adjusted_metrics(\n",
        "        y_test, y_pred_proba_global, eco_base_rate, original_threshold=0.5\n",
        "    )\n",
        "\n",
        "    # 初始化本地模型指标\n",
        "    oa_local = np.nan\n",
        "    f1_local = np.nan\n",
        "    pa_local = np.nan\n",
        "    ua_local = np.nan\n",
        "    kappa_local = np.nan\n",
        "    local_adj_metrics = {\n",
        "        'OA_adj': np.nan,\n",
        "        'F1_adj': np.nan,\n",
        "        'Kappa_adj': np.nan,\n",
        "        'PA_adj': np.nan,\n",
        "        'UA_adj': np.nan\n",
        "    }\n",
        "    local_model_trained = data['local_model_trained']\n",
        "\n",
        "    # 如果有本地模型，计算本地模型性能\n",
        "    if local_model_trained and ecoregion_id in local_models:\n",
        "        local_model = local_models[ecoregion_id]\n",
        "        y_pred_local = local_model.predict(X_test)\n",
        "        y_pred_proba_local = local_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "        # 计算本地模型原始指标\n",
        "        oa_local = accuracy_score(y_test, y_pred_local)\n",
        "        f1_local = f1_score(y_test, y_pred_local, zero_division=0)\n",
        "        pa_local = recall_score(y_test, y_pred_local, zero_division=0)\n",
        "        ua_local = precision_score(y_test, y_pred_local, zero_division=0)\n",
        "        kappa_local = cohen_kappa_score(y_test, y_pred_local)\n",
        "\n",
        "        # 计算本地模型面积调整后的指标（使用生态区基础率）\n",
        "        local_adj_metrics = calculate_area_adjusted_metrics(\n",
        "            y_test, y_pred_proba_local, eco_base_rate, original_threshold=0.5\n",
        "        )\n",
        "\n",
        "    # 记录结果\n",
        "    results.append({\n",
        "        'ecoregion': ecoregion_id,\n",
        "        'n_total': data['n_total'],\n",
        "        'n_train': len(data['X_train']),\n",
        "        'n_test': len(X_test),\n",
        "        'positive_ratio': data['positive_ratio'],\n",
        "        'base_rate': eco_base_rate,\n",
        "\n",
        "        # 全局模型原始指标\n",
        "        'OA_global': oa_global,\n",
        "        'F1_global': f1_global,\n",
        "        'Kappa_global': kappa_global,\n",
        "        'PA_global': pa_global,\n",
        "        'UA_global': ua_global,\n",
        "\n",
        "        # 全局模型面积调整后指标\n",
        "        'OA_global_adj': global_adj_metrics['OA_adj'],\n",
        "        'F1_global_adj': global_adj_metrics['F1_adj'],\n",
        "        'Kappa_global_adj': global_adj_metrics['Kappa_adj'],\n",
        "        'PA_global_adj': global_adj_metrics['PA_adj'],\n",
        "        'UA_global_adj': global_adj_metrics['UA_adj'],\n",
        "\n",
        "        # 本地模型原始指标\n",
        "        'OA_local': oa_local,\n",
        "        'F1_local': f1_local,\n",
        "        'Kappa_local': kappa_local,\n",
        "        'PA_local': pa_local,\n",
        "        'UA_local': ua_local,\n",
        "\n",
        "        # 本地模型面积调整后指标\n",
        "        'OA_local_adj': local_adj_metrics['OA_adj'],\n",
        "        'F1_local_adj': local_adj_metrics['F1_adj'],\n",
        "        'Kappa_local_adj': local_adj_metrics['Kappa_adj'],\n",
        "        'PA_local_adj': local_adj_metrics['PA_adj'],\n",
        "        'UA_local_adj': local_adj_metrics['UA_adj'],\n",
        "\n",
        "        # 调整阈值\n",
        "        'adjusted_threshold': global_adj_metrics['adjusted_threshold'],\n",
        "\n",
        "        'local_model_trained': local_model_trained\n",
        "    })\n",
        "\n",
        "# 转换为DataFrame\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# 7. 计算全国尺度的面积调整指标\n",
        "print(f\"\\n7. 计算全国尺度的面积调整指标...\")\n",
        "\n",
        "if len(national_test_data) > 0:\n",
        "    # 准备全国测试数据\n",
        "    X_national_test = np.array([item['features'] for item in national_test_data])\n",
        "    y_national_test = np.array([item['label'] for item in national_test_data])\n",
        "\n",
        "    # 使用全局模型预测全国测试集\n",
        "    y_pred_national = global_model.predict(X_national_test)\n",
        "    y_pred_proba_national = global_model.predict_proba(X_national_test)[:, 1]\n",
        "\n",
        "    # 计算全局模型原始指标（1:1平衡采样）\n",
        "    oa_national = accuracy_score(y_national_test, y_pred_national)\n",
        "    f1_national = f1_score(y_national_test, y_pred_national, zero_division=0)\n",
        "    pa_national = recall_score(y_national_test, y_pred_national, zero_division=0)\n",
        "    ua_national = precision_score(y_national_test, y_pred_national, zero_division=0)\n",
        "    kappa_national = cohen_kappa_score(y_national_test, y_pred_national)\n",
        "\n",
        "    # 计算全局模型面积调整后的指标（使用全国基础率）\n",
        "    national_adj_metrics = calculate_area_adjusted_metrics(\n",
        "        y_national_test, y_pred_proba_national, national_base_rate, original_threshold=0.5\n",
        "    )\n",
        "\n",
        "    print(f\"  全国尺度全局模型性能:\")\n",
        "    print(f\"    原始指标 - OA={oa_national:.4f}, F1={f1_national:.4f}, Kappa={kappa_national:.4f}, PA={pa_national:.4f}, UA={ua_national:.4f}\")\n",
        "    print(f\"    面积调整后 - OA_adj={national_adj_metrics['OA_adj']:.4f}, F1_adj={national_adj_metrics['F1_adj']:.4f}, Kappa_adj={national_adj_metrics['Kappa_adj']:.4f}\")\n",
        "    print(f\"                PA_adj={national_adj_metrics['PA_adj']:.4f}, UA_adj={national_adj_metrics['UA_adj']:.4f}\")\n",
        "    print(f\"    调整阈值: {national_adj_metrics['adjusted_threshold']:.6f}\")\n",
        "else:\n",
        "    print(f\"  警告: 没有足够的全国测试数据\")\n",
        "    national_adj_metrics = {\n",
        "        'OA_adj': np.nan,\n",
        "        'F1_adj': np.nan,\n",
        "        'Kappa_adj': np.nan,\n",
        "        'PA_adj': np.nan,\n",
        "        'UA_adj': np.nan\n",
        "    }\n",
        "\n",
        "# 8. 保存结果\n",
        "print(f\"\\n8. 保存结果...\")\n",
        "\n",
        "# 创建汇总结果\n",
        "summary_results = {\n",
        "    'national_base_rate': national_base_rate,\n",
        "    'OA_national_original': oa_national if len(national_test_data) > 0 else np.nan,\n",
        "    'F1_national_original': f1_national if len(national_test_data) > 0 else np.nan,\n",
        "    'Kappa_national_original': kappa_national if len(national_test_data) > 0 else np.nan,\n",
        "    'PA_national_original': pa_national if len(national_test_data) > 0 else np.nan,\n",
        "    'UA_national_original': ua_national if len(national_test_data) > 0 else np.nan,\n",
        "    'OA_national_adj': national_adj_metrics['OA_adj'],\n",
        "    'F1_national_adj': national_adj_metrics['F1_adj'],\n",
        "    'Kappa_national_adj': national_adj_metrics['Kappa_adj'],\n",
        "    'PA_national_adj': national_adj_metrics['PA_adj'],\n",
        "    'UA_national_adj': national_adj_metrics['UA_adj'],\n",
        "    'n_ecoregions': len(ecoregion_data),\n",
        "    'n_test_samples_total': len(national_test_data) if len(national_test_data) > 0 else 0,\n",
        "    'global_model_training_time': global_training_time\n",
        "}\n",
        "\n",
        "# 转换为DataFrame并保存\n",
        "summary_df = pd.DataFrame([summary_results])\n",
        "summary_path = '/content/drive/MyDrive/global_vs_local_area_adjusted_summary.csv'\n",
        "summary_df.to_csv(summary_path, index=False)\n",
        "print(f\"  全国尺度汇总结果已保存到: {summary_path}\")\n",
        "\n",
        "# 保存详细结果\n",
        "detailed_path = '/content/drive/MyDrive/global_vs_local_area_adjusted_detailed.csv'\n",
        "results_df.to_csv(detailed_path, index=False)\n",
        "print(f\"  详细生态区结果已保存到: {detailed_path}\")\n",
        "\n",
        "# 9. 统计分析\n",
        "print(f\"\\n9. 统计分析...\")\n",
        "\n",
        "# 筛选出有本地模型的生态区\n",
        "valid_results = results_df[results_df['local_model_trained'] == True].copy()\n",
        "\n",
        "if len(valid_results) > 0:\n",
        "    print(f\"  有本地模型的生态区数量: {len(valid_results)}\")\n",
        "\n",
        "    # 计算平均性能（面积调整后）\n",
        "    mean_oa_global_adj = valid_results['OA_global_adj'].mean()\n",
        "    mean_f1_global_adj = valid_results['F1_global_adj'].mean()\n",
        "    mean_oa_local_adj = valid_results['OA_local_adj'].mean()\n",
        "    mean_f1_local_adj = valid_results['F1_local_adj'].mean()\n",
        "\n",
        "    print(f\"\\n  面积调整后的平均性能比较:\")\n",
        "    print(f\"    全局模型 - 平均OA_adj: {mean_oa_global_adj:.3f}, 平均F1_adj: {mean_f1_global_adj:.3f}\")\n",
        "    print(f\"    本地模型 - 平均OA_adj: {mean_oa_local_adj:.3f}, 平均F1_adj: {mean_f1_local_adj:.3f}\")\n",
        "\n",
        "    # 计算性能差异\n",
        "    mean_f1_diff_adj = mean_f1_local_adj - mean_f1_global_adj\n",
        "    mean_oa_diff_adj = mean_oa_local_adj - mean_oa_global_adj\n",
        "\n",
        "    print(f\"\\n  面积调整后平均性能差异 (本地模型 - 全局模型):\")\n",
        "    print(f\"    平均F1差异: {mean_f1_diff_adj:.3f}\")\n",
        "    print(f\"    平均OA差异: {mean_oa_diff_adj:.3f}\")\n",
        "\n",
        "# 10. 生成最终报告\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"10. 总结报告\")\n",
        "print(f\"{'='*80}\")\n",
        "\n",
        "report = f\"\"\"\n",
        "全局模型 vs 分区模型性能比较报告（包含面积调整）\n",
        "===========================================\n",
        "\n",
        "实验设置:\n",
        "- 全国PFCL基础率: {national_base_rate:.4%}\n",
        "- 总生态区数量: {df['ID'].nunique()}\n",
        "- 有效生态区数量: {len(ecoregion_data)}\n",
        "- 全局训练样本数: {len(X_global_train)}\n",
        "- 全国测试样本总数: {len(national_test_data)}\n",
        "\n",
        "模型配置:\n",
        "- 模型类型: 随机森林\n",
        "- 树数量: {rf_params['n_estimators']}\n",
        "- 最大深度: {rf_params['max_depth']}\n",
        "\n",
        "全国尺度面积调整结果:\n",
        "- 全国基础率: {national_base_rate:.4%}\n",
        "- OA_national_original: {oa_national:.4f} -> OA_national_adj: {national_adj_metrics['OA_adj']:.4f}\n",
        "- F1_national_original: {f1_national:.4f} -> F1_national_adj: {national_adj_metrics['F1_adj']:.4f}\n",
        "- Kappa_national_original: {kappa_national:.4f} -> Kappa_national_adj: {national_adj_metrics['Kappa_adj']:.4f}\n",
        "- PA_national_original: {pa_national:.4f} -> PA_national_adj: {national_adj_metrics['PA_adj']:.4f}\n",
        "- UA_national_original: {ua_national:.4f} -> UA_national_adj: {national_adj_metrics['UA_adj']:.4f}\n",
        "- 调整阈值: {national_adj_metrics['adjusted_threshold']:.6f}\n",
        "\n",
        "关键发现:\n",
        "\"\"\"\n",
        "\n",
        "if len(valid_results) > 0:\n",
        "    report += f\"\"\"\n",
        "生态区尺度平均性能（面积调整后）:\n",
        "- 全局模型平均F1_adj: {mean_f1_global_adj:.3f}\n",
        "- 本地模型平均F1_adj: {mean_f1_local_adj:.3f}\n",
        "- 平均F1差异 (本地-全局): {mean_f1_diff_adj:.3f}\n",
        "\"\"\"\n",
        "\n",
        "# 判断哪种模型更好\n",
        "if 'mean_f1_diff_adj' in locals() and mean_f1_diff_adj > 0.05:\n",
        "    report += \"\\n结论: 面积调整后，本地模型仍明显优于全局模型，生态区特异性建模具有优势。\"\n",
        "elif 'mean_f1_diff_adj' in locals() and mean_f1_diff_adj > 0:\n",
        "    report += \"\\n结论: 面积调整后，本地模型略有优势，但差异不大。\"\n",
        "elif 'mean_f1_diff_adj' in locals() and mean_f1_diff_adj < 0:\n",
        "    report += \"\\n结论: 面积调整后，全局模型反而表现更好，可能由于本地模型过拟合。\"\n",
        "else:\n",
        "    report += \"\\n结论: 面积调整后，两种模型性能相当。\"\n",
        "\n",
        "report += f\"\"\"\n",
        "\n",
        "输出文件:\n",
        "1. {summary_path} - 全国尺度汇总结果（包含面积调整）\n",
        "2. {detailed_path} - 详细生态区结果\n",
        "3. /content/drive/MyDrive/global_model_comparison.pkl - 全局模型文件\n",
        "\n",
        "面积调整的影响:\n",
        "- UA（用户精度）通常会大幅下降，因为基础率降低意味着假阳性相对增加\n",
        "- PA（生产者精度）变化较小，因为漏报率相对稳定\n",
        "- OA（总体精度）通常会上升，因为负类样本远多于正类\n",
        "- 调整阈值从0.5降低到{national_adj_metrics.get('adjusted_threshold', 0):.4f}，使模型对正类更敏感\n",
        "\"\"\"\n",
        "\n",
        "print(report)\n",
        "\n",
        "# 保存报告\n",
        "report_path = '/content/drive/MyDrive/global_vs_local_area_adjusted_report.txt'\n",
        "with open(report_path, 'w') as f:\n",
        "    f.write(report)\n",
        "\n",
        "print(f\"\\n报告已保存到: {report_path}\")\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"处理完成!\")\n",
        "print(f\"{'='*80}\")"
      ]
    }
  ]
}